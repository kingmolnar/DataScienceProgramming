{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvDJJwxUzUCU"
   },
   "source": [
    "\n",
    "\n",
    "# **IFI8410: Programming for Business**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKAsLR0C2DE8"
   },
   "source": [
    "## **Assignment 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9hXNg4GsNgD"
   },
   "outputs": [],
   "source": [
    "# Do not change the content of this cell. Execute this cell first, and everytime after you restarted the kernel.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9ztuo0IsNgE"
   },
   "source": [
    "##  Multiple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiXz48oz2NhW"
   },
   "source": [
    "### Problem 10.1: K-Fold Cross-Validation with Linear Regression\n",
    "\n",
    "Question:\n",
    "\n",
    "Write a function that performs **k-fold cross-validation** on the house price dataset using a Linear Regression model.\n",
    "\n",
    "- Use k-fold cross-validation with **k=5**.\n",
    "\n",
    "- Train a Linear Regression model on the training set.\n",
    "\n",
    "- Calculate the mean squared error (MSE) for the test set.\n",
    "\n",
    "- Return the average **MSE** across all folds.\n",
    "\n",
    "Requirements:\n",
    "- Set up k-fold cross-validation using the specified number of folds. Ensure that the data is shuffled before splitting.\n",
    "\n",
    "- Use `KFold` from `scikit-learn` for splitting the dataset.\n",
    "\n",
    "- Use LinearRegression from scikit-learn as the model.\n",
    "\n",
    "- Return the average MSE across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.280692Z",
     "start_time": "2024-09-30T18:29:21.186714Z"
    },
    "id": "R7-4vnbIzp-o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the k-fold cross-validation function\n",
    "def k_fold_cross_val_mse(data, target, k=5):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    return np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZWGO7ewZiOn",
    "outputId": "38d812c0-7066-4218-ac7e-62ad4e4e0887"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess11/HousePricePrediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the non-numeric 'date' column\n",
    "data = data.drop(columns=['date'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Call the function to perform k-fold cross-validation and print the result\n",
    "average_mse = k_fold_cross_val_mse(X, y)\n",
    "print(f\"Average MSE from 5-fold cross-validation: {average_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8laWEoeZiOn"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.651471Z",
     "start_time": "2024-09-30T18:29:21.545780Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SajRmT5AZiOn",
    "outputId": "7c46a959-0a5c-428c-fc78-d5f479d37374"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_1.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the k-fold cross-validation function\n",
    "def k_fold_cross_val_mse(data, target, k=5):\n",
    "\n",
    "    \n",
    "\n",
    "    return np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNknpBBrZiOn"
   },
   "source": [
    "#### Test 10.1 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.951769Z",
     "start_time": "2024-09-30T18:29:21.720115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YusNec-oZiOn",
    "outputId": "f4068423-d601-4837-e3d6-45caf76124f6"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.022361Z",
     "start_time": "2024-09-30T18:29:22.019044Z"
    },
    "id": "vQl3ctAXZiOn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qfed3KE2Wh9"
   },
   "source": [
    "### Problem 10.2: Leave-One-Out Cross-Validation with Linear Regression\n",
    "\n",
    "Description:\n",
    "\n",
    "Implement a function **loocv_mse** that performs leave-one-out cross-validation (LOOCV) on a given dataset using a Linear Regression model. The goal is to evaluate the Mean Squared Error (MSE) for a regression model trained with LOOCV.\n",
    "\n",
    "- For each data point in the dataset:\n",
    "\n",
    "- Train a Linear Regression model on all data points except the one left out.\n",
    "\n",
    "- Calculate the MSE for this left-out sample.\n",
    "\n",
    "- Finally, your function should return the average MSE across all leave-one-out splits.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use `LeaveOneOut()` from scikit-learn to perform **LOOCV**.\n",
    "\n",
    "- Use `LinearRegression()` from `scikit-learn` as the model.\n",
    "\n",
    "- Return the average **MSE** across all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.226699Z",
     "start_time": "2024-09-30T18:29:22.124362Z"
    },
    "id": "4cjZCE_Q2hN1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def loocv_mse(data, target):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    return np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8_Sh6VFZiOo",
    "outputId": "e9bb0700-917c-4317-9efd-fd3efcf12a90"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess11/HousePricePrediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the non-numeric 'date' column\n",
    "data = data.drop(columns=['date'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Call the function to perform leave-one-out cross-validation and print the result\n",
    "average_mse = loocv_mse(X, y)\n",
    "print(f\"Average MSE from Leave-One-Out Cross-Validation: {average_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlsMD8zXZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.551198Z",
     "start_time": "2024-09-30T18:29:22.451243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3WoLmN_ZiOo",
    "outputId": "5a0b9870-316c-4270-869a-a1d8f4ec7164"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_2.py\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def loocv_mse(data, target):\n",
    "\n",
    "\n",
    "    return np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6Zay9KIZiOo"
   },
   "source": [
    "#### Test 10.2 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.844763Z",
     "start_time": "2024-09-30T18:29:22.606809Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50Vqcn6oZiOo",
    "outputId": "2c73bf0c-2798-4b32-f28d-c25c182dd70b"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AUT5bJTiKZW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UguNN8jDZiOo"
   },
   "source": [
    "### Problem 10.3: Bootstrapping with Linear Regression\n",
    "\n",
    "Question:\n",
    "\n",
    "Write a function that performs **bootstrapping** to estimate the MSE of a Linear Regression model on the house price dataset.\n",
    "\n",
    "- Use bootstrapping to create 100 random samples with replacement from the dataset.\n",
    "\n",
    "- Train a Linear Regression model on the bootstrap sample.\n",
    "\n",
    "- Calculate the **Mean Squared Error (MSE)** on a random subset of data points not included in the bootstrap sample.\n",
    "\n",
    "- Return the average MSE across all bootstrap samples.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use the `LinearRegression()` model from `scikit-learn`.\n",
    "  \n",
    "- Generate 100 bootstrap samples and evaluate the model on a subset of data points not included in each bootstrap sample.\n",
    "\n",
    "- Return the average MSE across all bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTVwGNd_ZiOo"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_mse(data, target, n_bootstrap=100):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    return np.mean(mse_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSGIa-OUZiOo",
    "outputId": "a084ab14-b618-4556-b59a-8daa042e4184"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess11/HousePricePrediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the non-numeric 'date' column\n",
    "data = data.drop(columns=['date'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Call the function to perform bootstrapping and print the result\n",
    "average_mse = bootstrap_mse(X, y)\n",
    "print(f\"Average MSE from Bootstrapping: {average_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_In_ItuZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faaGepf2ZiOp",
    "outputId": "4aec546f-c28d-446d-a919-22bdc87690eb"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_3.py\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_mse(data, target, n_bootstrap=100):\n",
    "\n",
    "\n",
    "    return np.mean(mse_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rjDbFLWZiOp"
   },
   "source": [
    "#### Test 10.3 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBnZK_-EZiOp",
    "outputId": "a54e38f1-7178-48d8-9358-dd6a194d1956"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZzh2YMDiKZX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPZu6cQpiKZX"
   },
   "source": [
    "### Problem 10.4: Model Comparison with RMSE\n",
    "\n",
    "Question:\n",
    "\n",
    "Write a function that compares four different regression models—Linear Regression, Decision Tree, Random Forest, and XGBoost—using RMSE on a test set.\n",
    "\n",
    "- Split the dataset into an 80% training set and a 20% test set.\n",
    "\n",
    "- Train each model on the training data.\n",
    "\n",
    "- Calculate the **Root Mean Squared Error (RMSE)** for each model on the test set.\n",
    "\n",
    "- Return the RMSE values for each model.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use `train_test_split` from scikit-learn to split the dataset.\n",
    "\n",
    "- Train and evaluate the following models:\n",
    "\n",
    "    * Linear Regressor\n",
    "    \n",
    "    * Decision Tree Regressor\n",
    "    \n",
    "    * Random Forest Regressor\n",
    "    \n",
    "    * XGBoost Regressor\n",
    "\n",
    "- Return a dictionary with the RMSE for each model (use as model names\n",
    "    \"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"XGBoost\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJRnlEBNZiOp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_comparison_rmse(data, target):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    return rmse_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wWBWRBOiKZX",
    "outputId": "78e67075-829a-4127-c87d-278c10285dbb"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess11/HousePricePrediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the non-numeric 'date' column\n",
    "data = data.drop(columns=['date'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Call the function to compare models and print the RMSE for each\n",
    "rmse_results = model_comparison_rmse(X, y)\n",
    "for model_name, rmse in rmse_results.items():\n",
    "    print(f\"{model_name}: RMSE = {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR5K1qq9iKZX"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vuPVQ0ciKZX",
    "outputId": "2c5cdd10-b212-4add-fc5f-60e98ff7d876"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_4.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_comparison_rmse(data, target):\n",
    "\n",
    "\n",
    "    return rmse_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WQfm49WiKZX"
   },
   "source": [
    "#### Test 10.4 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0oHM-9JiKZX",
    "outputId": "fceff062-0249-4fcf-ee20-7f4e1f858771"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "049thGnAiKZb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3F103HXZiOp"
   },
   "source": [
    "### Problem 10.5: Model Comparison with R² Score\n",
    "\n",
    "Question:\n",
    "\n",
    "Write a function **model_comparison_r2**, that compares the performance of four different regression models — **Linear Regression, Decision Tree, Random Forest,** and **XGBoost** — by calculating their **R² scores** on a test set.\n",
    "\n",
    "- Split the dataset into an 80% training set and a 20% test set.\n",
    "\n",
    "- Train each model on the training data.\n",
    "\n",
    "- Calculate the **R²** score for each model on the test set.\n",
    "\n",
    "- Return the **R²** scores for each model.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use `train_test_split` from `scikit-learn` to split the dataset.\n",
    "\n",
    "- Train and evaluate the following models:\n",
    "\n",
    "    * Linear Regressor\n",
    "    \n",
    "    * Decision Tree Regressor\n",
    "    \n",
    "    * Random Forest Regressor\n",
    "    \n",
    "    * XGBoost Regressor\n",
    "\n",
    "- Return a dictionary with the R² score for each model (keys are the model names, values are the R² scores). See also problem 10.4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4bsfwWbZiOp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def model_comparison_r2(data, target):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "    return r2_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxaqQ98RiKZb",
    "outputId": "73f4e739-65ce-47a4-af5f-0fc7f7513e72"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess11/HousePricePrediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the non-numeric 'date' column\n",
    "data = data.drop(columns=['date'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Call the function to compare models and print the R² score for each\n",
    "r2_results = model_comparison_r2(X, y)\n",
    "for model_name, r2 in r2_results.items():\n",
    "    print(f\"{model_name}: R² Score = {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0Ltf0x9iKZb"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqxRRIuKiKZb",
    "outputId": "b3f487ee-510c-4a5d-c01d-0523424c0057"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_5.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def model_comparison_r2(data, target):\n",
    "\n",
    "\n",
    "    \n",
    "    return r2_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnWVfOb3ZiOp"
   },
   "source": [
    "#### Test 10.5 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEFhdc_7dGff",
    "outputId": "0028959d-19bb-4beb-e244-ed6abc12f30d"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QOys_gciKZb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKXQDWb1sNgO"
   },
   "source": [
    "### 10.6 precision, recall, F1-score\n",
    "\n",
    "Question:\n",
    "\n",
    "Description:\n",
    "\n",
    "You are tasked with evaluating the performance of three different classifiers on a dataset: Decision Tree (DT), Random Forest (RF), and XGBoost. The goal is to assess and compare their **precision, recall, and F1-score**.\n",
    "\n",
    "To accomplish this, follow these steps:\n",
    "\n",
    "**Data Preprocessing**:\n",
    "\n",
    "- Handle categorical variables appropriately, using one-hot encoding where necessary.\n",
    "\n",
    "**Data Splitting**:\n",
    "\n",
    "- Split your dataset into an 80% training set and a 20% test set.\n",
    "\n",
    "**Model Training**:\n",
    "\n",
    "- Implement each classifier (DecisionTreeClassifier, RandomForestClassifier, and XGBClassifier) and train it on the training data.\n",
    "\n",
    "**Model Evaluation**:\n",
    "\n",
    "- After training, make predictions on the test set.\n",
    "\n",
    "- Calculate **precision, recall,** and **F1-score** using `precision_score`, `recall_score`, and `f1_score` from `sklearn.metrics`.\n",
    "\n",
    "**Result Formatting**:\n",
    "\n",
    "- For each classifier, round each metric to 4 decimal places.\n",
    "\n",
    "- Return a dictionary containing **precision, recall,** and **F1-score** for each model (use as model names 'Decision Tree', 'Random Forest', 'XGBoost').\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Use `OneHotEncoder()` to handle categorical features, and integrate it into a `ColumnTransformer()`.\n",
    "\n",
    "- Create a **pipeline** for each classifier, which includes preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSAXDUwD07Cx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_evaluate_classifier(X_train, X_test, y_train, y_test, classifier, classifier_name):\n",
    "\n",
    "\n",
    "    \n",
    "    return {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "def get_metrics(X_train, X_test, y_train, y_test):\n",
    "\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'Decision Tree': dt_metrics,\n",
    "        'Random Forest': rf_metrics,\n",
    "        'XGBoost': xgb_metrics\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMtBjdrYsNgO",
    "outputId": "00b49b12-a021-4799-ecb3-5d35ab6275ec"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = '/data/IFI8410/sess11/Fraud_complete.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features and target\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "# Data preprocessing\n",
    "X = df[categorical_features]\n",
    "y = df[target_feature]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Get metrics\n",
    "metrics = get_metrics(X_train, X_test, y_train, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZyWUKqasNgO"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AC2XYbu807Cx"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_6.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_evaluate_classifier(X_train, X_test, y_train, y_test, classifier, classifier_name):\n",
    "\n",
    "\n",
    "    \n",
    "    return {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "def get_metrics(X_train, X_test, y_train, y_test):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'Decision Tree': dt_metrics,\n",
    "        'Random Forest': rf_metrics,\n",
    "        'XGBoost': xgb_metrics\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/data/IFI8410/sess10/Fraud_data.csv'\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "X = df[categorical_features]\n",
    "y = df[target_feature]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "metrics = get_metrics(X_train, X_test, y_train, y_test)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y780TWF1sNgO"
   },
   "source": [
    "#### Test 10.6 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW0lVc3_sNgO",
    "outputId": "ad0dbe58-e6f9-4489-99d5-017e36b5fa1c"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaIXr3nQsNgP"
   },
   "source": [
    "### 10.7 Average class accuracy\n",
    "\n",
    "You are tasked with evaluating the average class accuracy for three different classifiers — **Decision Tree (DT), Random Forest (RF), and XGBoost** — on a dataset containing various categorical features related to fraud detection.\n",
    "\n",
    "The function should:\n",
    "\n",
    "**Data Preprocessing**:\n",
    "\n",
    "- Apply one-hot encoding to the categorical features.\n",
    "\n",
    "- Encode the target feature using `LabelEncoder()`.\n",
    "\n",
    "- Split the data into a 70% training set and a 30% test set.\n",
    "\n",
    "**Model Training**:\n",
    "\n",
    "- Train each classifier (Decision Tree, Random Forest, XGBoost) on the training data.\n",
    "\n",
    "**Model Evaluation**:\n",
    "\n",
    "- For each classifier, predict the labels on the test set.\n",
    "\n",
    "- Calculate the average class accuracy using balanced_accuracy_score (or manually compute it using confusion matrix as shown).\n",
    "\n",
    "**Result Formatting**:\n",
    "\n",
    "- Return a dictionary containing the average class accuracy (rounded to 4 decimal places) for each model. See also problem 10.6.\n",
    "  \n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Create two functions:\n",
    "\n",
    "  * First, define a function `calculate_average_class_accuracy(y_true, y_pred, class_labels)` that computes the average class accuracy and returns that value as a floating point result.\n",
    "\n",
    "  * Integrate one-hot encoding for categorical variables using a `Pipeline` to streamline the preprocessing.\n",
    "\n",
    "  * Then  define a function `train_and_evaluate_models(file_path, categorical_features, target_feature)` that trains and evaluates a model and calls `calculate_average_class_accuracy(.)` in a loop over the different classifier models to return a dictionary that contains as keys the names of the classifier models and as values the average class accuracy of each model as final result.\n",
    "\n",
    "  * Note: You can define the names associated with the models via a separate dictionary in your function:\n",
    " \n",
    "    `classifiers = {\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=1),\n",
    "        'Random Forest': RandomForestClassifier(random_state=1),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=1)\n",
    "    }`\n",
    " \n",
    "    \n",
    "    Then use e.g. `for name, clf in classifiers.items(): ...` for your loop.\n",
    " \n",
    "  * Save both functions in your final  solution file **solution_10_7.py**.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gmoo71_G07Cy",
    "outputId": "94d0c279-cc61-444e-c9c7-291224bfccd4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def calculate_average_class_accuracy(y_true, y_pred, class_labels):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "    \n",
    "    return average_class_accuracy\n",
    "\n",
    "def train_and_evaluate_models(file_path, categorical_features, target_feature):\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKY6WmTVsNgP",
    "outputId": "f61fc8db-ca70-4963-c023-5bc0347410fe"
   },
   "outputs": [],
   "source": [
    "# Usage\n",
    "file_path = '/data/IFI8410/sess11/Fraud_complete.csv'\n",
    "categorical_features = ['Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType', 'VehicleCategory', 'PoliceReportFiled', 'WitnessPresent', 'BasePolicy']\n",
    "target_feature = 'FraudFound_P'\n",
    "class_accuracies = train_and_evaluate_models(file_path, categorical_features, target_feature)\n",
    "print(\"Class Accuracies:\", class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAzNgSTAsNgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kvVrviLsNgP"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bks29yrDTGkg",
    "outputId": "c76bda80-b45c-4aeb-b38b-d4df92055fa9"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_7.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def calculate_average_class_accuracy(y_true, y_pred, class_labels):\n",
    "\n",
    "\n",
    "    \n",
    "    return average_class_accuracy\n",
    "\n",
    "def train_and_evaluate_models(file_path, categorical_features, target_feature):\n",
    "\n",
    "\n",
    "    \n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBHL10UzsNgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSKuQSyusNgP"
   },
   "source": [
    "#### Test 10.7 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaXPg3mksNgP",
    "outputId": "bc5adfe3-39f9-47fb-9d90-615ba0bfef03"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSuCGrZTsNgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-MGDweKsNgP"
   },
   "source": [
    "### 10.8 confusion matrix with TP, FP, TN, FN\n",
    "\n",
    "**Question:**\n",
    "\n",
    "You are provided with a dataset **Fraud_complete.csv** which contains various features related to insurance claims. \n",
    "\n",
    "Your task is to build classifiers using **Decision Tree, Random Forest,** and **XGBoost** to predict a binary target variable **FraudFound_P.** \n",
    "\n",
    "For each classifier, calculate the **confusion matrix** and extract the **True Positives (TP), False Positives (FP), True Negatives (TN),** and **False Negatives (FN).**\n",
    "\n",
    "Return a nested dictionary named `confusion_matrices` (dictionary of dictionaries where the values are dictionaries of the form:\n",
    "\n",
    "`confusion_matrices[name] = {'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN}`\n",
    "\n",
    "The key **name** is the model name. Use 'Decision Tree', 'Random Forest', 'XGBoost' as model names.\n",
    "\n",
    "\n",
    "**Hint**: \n",
    "\n",
    "- Utilize the `confusion_matrix` function from `sklearn.metrics` to calculate the confusion matrices for each classifier after training.\n",
    "  \n",
    "- Ensure to split your dataset into training and testing sets to evaluate the models properly.\n",
    "\n",
    "- Use `OneHotEncoder` for categorical variables as part of your preprocessing steps.\n",
    "\n",
    "- The `confusion_matrix` function from `sklearn` returns values in the order of TN, FP, FN, TP when reshaped or indexed appropriately. (Use `cm.ravel()` to achieve that.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rk17o2oS07Cz",
    "outputId": "49d780d7-3986-4596-92aa-0d5ec2637d2d"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define a function to train classifiers and compute confusion matrices\n",
    "def train_and_evaluate(file_path, categorical_features, target_feature):\n",
    "\n",
    "    # Write your code here\n",
    "    \n",
    "\n",
    "\n",
    "    return confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lc9LkKY8sNgP",
    "outputId": "df2e7f56-42ec-4b31-a064-1e9e81e1d663"
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = '/data/IFI8410/sess11/Fraud_complete.csv'  # Adjust the file path\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "# Call the function\n",
    "confusion_results = train_and_evaluate(file_path, categorical_features, target_feature)\n",
    "print(confusion_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od_9vWdxsNgP"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpKm68gpsNgP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_d-BJbdsNgP",
    "outputId": "b3ec3dc4-c4e2-471b-d359-2da823f7fb10"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_8.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define a function to train classifiers and compute confusion matrices\n",
    "def train_and_evaluate(file_path, categorical_features, target_feature):\n",
    "\n",
    "\n",
    "    \n",
    "    return confusion_matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXgyEfH6sNgP"
   },
   "source": [
    "#### Test 10.8 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKASlAvrsNgQ",
    "outputId": "20ec154a-ce84-4563-ef10-7fca0ba7f350"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3XbJqrKsNgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB42utMcsNgQ"
   },
   "source": [
    "### 10.9 PR curve and ROC curve (with plot)\n",
    "\n",
    "Question: \n",
    "\n",
    "Implement and evaluate a Naive Bayes classifier on a dataset to predict fraudulent transactions. \n",
    "\n",
    "Specifically, visualize the model's performance using **Precision-Recall (PR)** and **Receiver Operating Characteristic (ROC) curves**.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Data Preparation: Start by loading the dataset and selecting the appropriate features and target. Perform any necessary preprocessing, such as encoding categorical variables if needed.\n",
    "\n",
    "- Model Training: Use the **Naive Bayes classifier** for training the model. Naive Bayes works well with categorical input features, especially for classification tasks.\n",
    "\n",
    "- Evaluation: After training the model, predict probabilities to use in calculating the PR and ROC curves. Use `roc_curve` and `precision_recall_curve` from `sklearn.metrics` to generate these curves.\n",
    "\n",
    "- Plotting: Use `matplotlib` to plot both the PR and ROC curves. This will help in visually assessing the model's ability to discriminate between the classes under different threshold settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytI7HFRMsNgQ",
    "outputId": "4fea9fa5-6d65-4143-8d47-0f90873a8290"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curves(file_path: str, categorical_features: list, target_feature: str) -> None:\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out your solution:\n",
    "\n",
    "# Load dataset\n",
    "file_path = '/data/IFI8410/sess11/Fraud_complete.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features and target\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "plot_curves(file_path, categorical_features, target_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ5oZuUasNgQ"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_9.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curves(file_path: str, categorical_features: list, target_feature: str) -> None:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqdmANCc07C0"
   },
   "source": [
    "#### Test 10.9 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUXxLM7U07C0"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG2Y-qitsNgQ"
   },
   "source": [
    "### 10.10 AuC (area under ROC curve)\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Implement a function to determine the Area Under the ROC Curve (AUC) for a Logistic Regression model trained to predict fraudulent transactions using the dataset provided at **/data/IFI8410/sess11/Fraud_complete.csv**.\n",
    "\n",
    "\n",
    "Two Steps:\n",
    "\n",
    "**Data Loading and Preprocessing**:\n",
    "\n",
    "- Load the dataset.\n",
    "\n",
    "- Preprocess the data by encoding categorical variables using one-hot encoding and encode the target variable as a binary label.\n",
    "\n",
    "  \n",
    "**Model Training and Evaluation**:\n",
    "\n",
    "- Split the data into a 70% training set and a 30% test set.\n",
    "\n",
    "- Train a Logistic Regression model using the preprocessed training data.\n",
    "  \n",
    "- Predict the probabilities on the test set.\n",
    "  \n",
    "- Calculate and return the AUC score using roc_auc_score from sklearn.metrics.\n",
    "\n",
    "  \n",
    "**Hint**:\n",
    "\n",
    "- You can do this in two steps with two separate function definitions:\n",
    "\n",
    "    `load_and_preprocess_data(file_path: str, categorical_features: list, target_feature: str)`\n",
    "\n",
    "    `train_logistic_regression(X, y, categorical_features: list)`\n",
    "\n",
    "- `load_and_preprocess_data` shall return X, y. `train_logistic_regression` shall return auc.\n",
    "\n",
    "- These functions should be run sequentially. See example to try out code below. Save both functions in **solution_10_10.py**\n",
    "\n",
    "- Use `ColumnTransformer` and `OneHotEncoder` for encoding categorical features.\n",
    " \n",
    "- The `roc_auc_score` function calculates AUC when provided with true labels and predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYlB85ZX07C0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def load_and_preprocess_data(file_path: str, categorical_features: list, target_feature: str):\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "    \n",
    "\n",
    "    return X, y\n",
    "\n",
    "def train_logistic_regression(X, y, categorical_features: list):\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "    \n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YVMVbK9sNgQ",
    "outputId": "ac4507f6-b517-4490-a287-c71a30f384b5"
   },
   "outputs": [],
   "source": [
    "# Load dataset and define features\n",
    "file_path = '/data/IFI8410/sess11/Fraud_complete.csv'\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "# Load and preprocess data\n",
    "X, y = load_and_preprocess_data(file_path, categorical_features, target_feature)\n",
    "\n",
    "# Train model and get AUC\n",
    "auc = train_logistic_regression(X, y, categorical_features)\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72k2V5etsNgQ"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRQk658HsNgQ",
    "outputId": "9d17f4db-4f86-4e75-9fbb-82f84ada63e5"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_10_10.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def load_and_preprocess_data(file_path: str, categorical_features: list, target_feature: str):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return X, y\n",
    "    \n",
    "def train_logistic_regression(X, y, categorical_features: list):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfIOKqTVsNgR"
   },
   "source": [
    "#### Test 10.10 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMw2m91XsNgR",
    "outputId": "92939f92-7e02-406b-a214-4a5abd6cad5e"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHlYhXH11dsJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHS2zsUfARtv"
   },
   "source": [
    "# Run all the tests again ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPxwUHEd1dul",
    "outputId": "711bd0ba-a354-4749-8cbc-1a2369e3d470"
   },
   "outputs": [],
   "source": [
    "! ./test/run_test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXV85d2wAVx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-HgeLbAYpq"
   },
   "source": [
    "#Homework Submission\n",
    "\n",
    "- This homework is due by **2024-11-20, 6:00 PM (EDT)**.\n",
    "\n",
    "- Make sure that all your programs and output files are in the exact folder as specified in the instructions.\n",
    "\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Execute the cell below to submit your assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwZl5dXMZiOp",
    "outputId": "2b39074e-7488-4143-a5a2-b0541420acd7"
   },
   "outputs": [],
   "source": [
    "! ./submit.sh -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
