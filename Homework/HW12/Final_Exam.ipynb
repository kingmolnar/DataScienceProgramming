{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvDJJwxUzUCU"
   },
   "source": [
    "\n",
    "\n",
    "# **IFI8410: Programming for Business**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKAsLR0C2DE8"
   },
   "source": [
    "## **Final Exam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9hXNg4GsNgD"
   },
   "outputs": [],
   "source": [
    "# Do not change the content of this cell. Execute this cell first, and everytime after you restarted the kernel.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = '/data/IFI8410/finalexam/HR_Analytics.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target feature for binary classification:\n",
    "data.loc[data['salary'] == 'low', 'binary_salary'] = 0\n",
    "data.loc[data['salary'] == 'medium', 'binary_salary'] = 0\n",
    "data.loc[data['salary'] == 'high', 'binary_salary'] = 1\n",
    "data['binary_salary'] = data['binary_salary'].astype(int)\n",
    "data.drop(columns=['salary'], inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiXz48oz2NhW"
   },
   "source": [
    "### Problem 1: Train a decision tree classification model on a dataset.\n",
    "\n",
    "Write a function that processes the **HR_Analytics.csv** dataset and trains a Decision Tree classifier to predict fraud:\n",
    "\n",
    "`process_and_train_decision_tree(df: pd.DataFrame, categorical_features: list) -> tuple:`\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "- Load and preprocess the data by one-hot encoding categorical columns.\n",
    "- Split the dataset into training and test sets with a 70:30 ratio.\n",
    "- Train a DecisionTreeClassifier model using the training data.\n",
    "- Evaluate the model using accuracy, precision, recall, and F1-score on the test set.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use a `OneHotEncoder` to encode categorical features, ensuring unknown levels are ignored.\n",
    "- The first category is dropped, and dense output is returned.\n",
    "- Return the calculated metrics **accuracy, precision, recall, F1-score** on the test set in the function output.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Use as target feature **binary_salary**; it describes whether a person's salary is Low (target label = 0) or Medium/High (target label = 1).\n",
    "- **Splitting the Data into Training and Test Data:** Use `train_test_split` with a 70% train and 30% test split.\n",
    "- **One-Hot Encoding of Categorical Features:** Apply OneHotEncoder on the categorical columns, setting parameters to ignore unknown values, drop the first level, and return a dense matrix.\n",
    "- **Numeric Features:** Make sure that all your numeric features are actually numeric.\n",
    "- **Model Training:** Use `DecisionTreeClassifier` to train on the training data. Simply use `DecisionTreeClassifier(random_state=1)`.\n",
    "- **Metrics Calculation:** Use scikit-learnâ€™s **accuracy_score, precision_score, recall_score,** and **f1_score** functions to return all the classification metrics in your final output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.280692Z",
     "start_time": "2024-09-30T18:29:21.186714Z"
    },
    "id": "R7-4vnbIzp-o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_decision_tree(df: pd.DataFrame, categorical_features: list, target_feature: str) -> tuple:\n",
    "    \n",
    "    # Write your code here\n",
    "        \n",
    "\n",
    "    \n",
    "    return accuracy, precision, recall, f1score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8laWEoeZiOn"
   },
   "source": [
    "#### Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataset:\n",
    "df = data.copy()\n",
    "\n",
    "# Separate numeric, categorical and numeric features:\n",
    "numerical_features = [\n",
    "    'satisfaction_level',\n",
    "    'last_evaluation',\n",
    "    'number_project',\n",
    "    'average_montly_hours',\n",
    "    'time_spend_company',\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Work_accident',\n",
    "    'left',\n",
    "    'promotion_last_5years',\n",
    "    'Department',\n",
    "]\n",
    "\n",
    "target_feature = 'binary_salary'\n",
    "\n",
    "# Run the training and evaluation function\n",
    "accuracy, precision, recall, f1score = process_and_train_decision_tree(df, categorical_features, target_feature)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.651471Z",
     "start_time": "2024-09-30T18:29:21.545780Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SajRmT5AZiOn",
    "outputId": "7c46a959-0a5c-428c-fc78-d5f479d37374"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_1.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_decision_tree(df: pd.DataFrame, categorical_features: list, target_feature: str) -> tuple:\n",
    "\n",
    "\n",
    "    \n",
    "    return accuracy, precision, recall, f1score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNknpBBrZiOn"
   },
   "source": [
    "#### Test 1: Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.951769Z",
     "start_time": "2024-09-30T18:29:21.720115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YusNec-oZiOn",
    "outputId": "f4068423-d601-4837-e3d6-45caf76124f6"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.022361Z",
     "start_time": "2024-09-30T18:29:22.019044Z"
    },
    "id": "vQl3ctAXZiOn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qfed3KE2Wh9"
   },
   "source": [
    "### Problem 2: Train a kNN classification model on a dataset\n",
    "\n",
    "You are given the above dataset from Problem 1 with several features and a target column. Your task is to implement a **KNN classifier** that includes necessary preprocessing steps to handle both categorical and numerical data.\n",
    "\n",
    "The aim is to build a reliable **KNN** model using **k=3** with optimized preprocessing.\n",
    "\n",
    "Write a function `knn_salary_classification(data)`.\n",
    "\n",
    "\n",
    "Problem Statement:\n",
    "\n",
    "Implement the function `knn_salary_classification` that will:\n",
    "\n",
    "- Take the dataset as a pandas DataFrame as input.\n",
    "\n",
    "- Apply preprocessing to one-hot encode categorical features. Use **Label Encoding**.\n",
    "\n",
    "- Train a KNN classifier using **k=3**.\n",
    "\n",
    "Evaluate the classifier using the testing set and return the **accuracy** of the classifer and the **classification report** (that includes metrics like precision, recall, and F1-score) as tuple in the function's final output.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Use as feature columns within the function following list of column names:\n",
    "\n",
    "    `feature_columns = [\n",
    "        'satisfaction_level',\n",
    "        'last_evaluation',\n",
    "        'number_project',\n",
    "        'average_montly_hours',\n",
    "        'time_spend_company',\n",
    "        'Work_accident',\n",
    "        'left',\n",
    "        'promotion_last_5years',\n",
    "        'Department'\n",
    "    ]`\n",
    "\n",
    "- Use as target columnn **binary_salary**.\n",
    "- Use the `LabelEncoder` from `sklearn.preprocessing` for categorical variables.\n",
    "- Use `KNeighborsClassifier` for the kNN classifier model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.226699Z",
     "start_time": "2024-09-30T18:29:22.124362Z"
    },
    "id": "4cjZCE_Q2hN1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_salary_classification(data):\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return accuracy, report\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8_Sh6VFZiOo",
    "outputId": "e9bb0700-917c-4317-9efd-fd3efcf12a90"
   },
   "outputs": [],
   "source": [
    "# Copy the dataset:\n",
    "df = data.copy()\n",
    "\n",
    "# Call the function using the full dataset\n",
    "accuracy, report = knn_salary_classification(df)\n",
    "\n",
    "# Display the full dataset results\n",
    "print(\"\\nAccuracy of KNN Salary Classification (k=3):\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlsMD8zXZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.551198Z",
     "start_time": "2024-09-30T18:29:22.451243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3WoLmN_ZiOo",
    "outputId": "5a0b9870-316c-4270-869a-a1d8f4ec7164"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_2.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_salary_classification(data):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return accuracy, report\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6Zay9KIZiOo"
   },
   "source": [
    "#### Test 2 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.844763Z",
     "start_time": "2024-09-30T18:29:22.606809Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50Vqcn6oZiOo",
    "outputId": "2c73bf0c-2798-4b32-f28d-c25c182dd70b"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UguNN8jDZiOo"
   },
   "source": [
    "### Problem 3: Train a Naive-Bayes classification model on a dataset\n",
    "\n",
    "Evaluate a **Naive Bayes model** on a test dataset using common classification metrics.\n",
    "\n",
    "For this purpose, create a function `naive_bayes_metrics(df, categorical_features, target_feature)` which takes the dataset as pandas DataFrame, the categorical features as list and the target feature as a string as input variables.\n",
    "\n",
    "**Important:** In this problem only the categorical features are used as input features for model training. You can drop the numerical features. Use \n",
    "the following list of categorical imnput features: `['Work_accident','left','promotion_last_5years','Department']`\n",
    "\n",
    "as categorical input features.\n",
    "\n",
    "After training your **Naive Bayes model** on a training set, evaluate the model on the test set by calculating the following metrics:\n",
    "\n",
    "- **Accuracy:** The overall proportion of correct predictions.\n",
    "\n",
    "- **Precision:** The proportion of true positive predictions out of all positive predictions.\n",
    "\n",
    "- **Recall:** The proportion of true positive predictions out of all actual positives.\n",
    "\n",
    "- **F1-Score:** The harmonic mean of precision and recall, providing a balance between the two.\n",
    "\n",
    "Return the final result in form of a dictionary: `{ \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1 }`\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Performn a 70:30 train-test split of your input dataframe to create training and test data sets.\n",
    "\n",
    "- One-hot encode the categorical features. You can use `OneHotEncoder` from `sklearn.preprocessing`.\n",
    "\n",
    "- Use `MultinomialNB(alpha=1.0)` from `sklearn.naive_bayes` to train your Naive-Bayes classification model.\n",
    "\n",
    "- You can use `ColumnTransformer` and `Pipeline` from `sklearn` to perform the feature pre-processing and model training together in one machine-learning pipeline.\n",
    "  \n",
    "- You can use **accuracy_score, precision_score, recall_score,** and **f1_score** from `sklearn.metrics` to compute the metrics.\n",
    "\n",
    "- Ensure that **y_test** (the original test labels) and **y_pred** (the predicted test labels) are arrays of the same shape and data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTVwGNd_ZiOo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def naive_bayes_metrics(df: pd.DataFrame, categorical_features: list, target_feature: str) -> dict:\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSGIa-OUZiOo",
    "outputId": "a084ab14-b618-4556-b59a-8daa042e4184"
   },
   "outputs": [],
   "source": [
    "# Copy the dataset:\n",
    "df = data.copy()\n",
    "\n",
    "# Define numerical, categorical and target features:\n",
    "# numerical_features = [\n",
    "#     'satisfaction_level',\n",
    "#     'last_evaluation',\n",
    "#     'number_project',\n",
    "#     'average_montly_hours',\n",
    "#     'time_spend_company',\n",
    "# ]\n",
    "\n",
    "categorical_features = [\n",
    "    'Work_accident',\n",
    "    'left',\n",
    "    'promotion_last_5years',\n",
    "    'Department',\n",
    "]\n",
    "\n",
    "target_feature = 'binary_salary'\n",
    "\n",
    "# Call the function using the dataset and the list of categorical features and the target feature\n",
    "metrics = naive_bayes_metrics(df, categorical_features, target_feature)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "print(f\"F1-Score: {metrics['f1_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_In_ItuZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faaGepf2ZiOp",
    "outputId": "4aec546f-c28d-446d-a919-22bdc87690eb"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_3.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def naive_bayes_metrics(df: pd.DataFrame, categorical_features: list, target_feature: str) -> dict:\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rjDbFLWZiOp"
   },
   "source": [
    "#### Test 3 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBnZK_-EZiOp",
    "outputId": "a54e38f1-7178-48d8-9358-dd6a194d1956"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZzh2YMDiKZX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPZu6cQpiKZX"
   },
   "source": [
    "### Problem 4: Train a Linear Regression model on a dataset\n",
    "\n",
    "Analyze and preprocess the **predict_home_value.csv** dataset to prepare it for a linear regression model that predicts house prices.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "**Important:** For this problem, only use the **numeric features** in the dataset for model training. \n",
    "\n",
    "\n",
    "Split the Dataset:\n",
    "\n",
    "- Create a function `select_and_split_data(df, numeric_columns, target_column)` that takes in the dataset as pandas DataFrame, the numeric columns and the target column to split the dataset into training and test sets.\n",
    "- Split the data into training and test sets with an **80:20** ratio.\n",
    "- Use **SALEPRICE** as the target column.\n",
    "- The function shall return the training and test datasets for model training and evaluation, **X_train, X_test, y_train, y_test**.\n",
    "\n",
    "\n",
    "Transform Features and Train Regression Model:\n",
    "\n",
    "- Create a function `preprocess_train_and_evaluate_model(X_train, X_test, y_train, y_test, numeric_columns)` that then preprocesses the numeric features and trains the ML model on the trainig data and evaluates it on the test data.\n",
    "\n",
    "- As numerical columns you can use `['LOTAREA', 'OVERALLCOND', 'YEARBUILT', 'FULLBATH', 'HALFBATH',\n",
    "       'BEDROOMABVGR', 'KITCHENABVGR', 'TOTRMSABVGRD', 'FIREPLACES',\n",
    "       'GARAGECARS', 'POOLAREA', 'MOSOLD', 'YRSOLD']`\n",
    "\n",
    "- Normalize or scale the numerical columns.\n",
    "\n",
    "- Predict house values for **X_test** via linear regression.\n",
    "\n",
    "- Calculate and return **MAE (mean absolute error), MSE (mean squared error),** and **RMSE (root mean squared error)** as regression evaluation metrics.\n",
    "\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Use `StandardScaler` from `sklearn.preprocessing` for normalization of numeric features.\n",
    "\n",
    "- Use `LinearRegression()` from `sklearn` to fit the model on the training data **X_train, y_train**.\n",
    "\n",
    "- You can use `ColumnTransformer` and `Pipeline` from `sklearn` to perform the feature pre-processing and model training together in one machine-learning pipeline.\n",
    "\n",
    "- Use **mean_absolute_error, mean_squared_error** from `sklearn` and **np.sqrt()** to calculate the three evaluation metrics based on the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset for regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "file_path = '/data/IFI8410/finalexam/predict_home_value.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['ID', 'POOLQC', 'FENCE'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = data.select_dtypes(\n",
    "    include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    ").columns\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['LOTAREA', 'OVERALLCOND', 'YEARBUILT', 'FULLBATH', 'HALFBATH',\n",
    "       'BEDROOMABVGR', 'KITCHENABVGR', 'TOTRMSABVGRD', 'FIREPLACES',\n",
    "       'GARAGECARS', 'POOLAREA', 'MOSOLD', 'YRSOLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'SALEPRICE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJRnlEBNZiOp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def select_and_split_data(\n",
    "    df: pd.DataFrame, numeric_columns: list, target_column: str = 'SALEPRICE'\n",
    ") -> tuple:\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def preprocess_train_and_evaluate_model(\n",
    "    X_train, X_test, y_train, y_test, numeric_columns\n",
    ") -> tuple:\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n",
    "\n",
    "    return mae, mse, rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "numeric_columns = ['LOTAREA', 'OVERALLCOND', 'YEARBUILT', 'FULLBATH', 'HALFBATH',\n",
    "       'BEDROOMABVGR', 'KITCHENABVGR', 'TOTRMSABVGRD', 'FIREPLACES',\n",
    "       'GARAGECARS', 'POOLAREA', 'MOSOLD', 'YRSOLD']\n",
    "\n",
    "target_column = 'SALEPRICE'\n",
    "\n",
    "X_train, X_test, y_train, y_test = select_and_split_data(df, numeric_columns, target_column)\n",
    "\n",
    "mae, mse, rmse = preprocess_train_and_evaluate_model(X_train, X_test, y_train, y_test, numeric_columns)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR5K1qq9iKZX"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vuPVQ0ciKZX",
    "outputId": "2c5cdd10-b212-4add-fc5f-60e98ff7d876"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_4.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def select_and_split_data(\n",
    "    df: pd.DataFrame, numeric_columns: list, target_column: str = 'SALEPRICE'\n",
    ") -> tuple:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def preprocess_train_and_evaluate_model(X_train, X_test, y_train, y_test, numeric_columns: list) -> tuple:\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return mae, mse, rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WQfm49WiKZX"
   },
   "source": [
    "#### Test 4 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0oHM-9JiKZX",
    "outputId": "fceff062-0249-4fcf-ee20-7f4e1f858771"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "049thGnAiKZb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3F103HXZiOp"
   },
   "source": [
    "### Problem 5: Compare the results of KMEANS Clustering and Agglomerative Hierarchical Clustering (AHC) on a dataset\n",
    "\n",
    "A dataset is prepared for you that uses `make_moons` from `sklearn.datasets` to generate a dataset with two interleaved half-moon shapes (Dataset Parameters: n_samples=500 (500 data points), noise=0.2 (introduce noise for complexity), random_state=42 (ensure reproducibility))\n",
    "\n",
    "You are tasked to compare two different clustering techniques on this complex dataset.\n",
    "\n",
    "The goal is to understand how each method performs on non-linear (two-dimensional) data and visualize the clustering results.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "**Apply the following two clustering algorithms to the dataset:**\n",
    "\n",
    "**KMeans++:**\n",
    "- Use `KMeans` from `sklearn.cluster`.\n",
    "- Initialization method: **k-means++**.\n",
    "- Number of clusters: 2.\n",
    "\n",
    "**Agglomerative Hierarchical Clustering (AHC):**\n",
    "- Use `AgglomerativeClustering` from `sklearn.cluster`.\n",
    "- Number of clusters: 2.\n",
    "\n",
    "**Visualize Clustering Results:** For each clustering method:\n",
    "- Plot the data points colored by their assigned cluster.\n",
    "- Display all six clustering results side by side in a 2x3 grid for comparison.\n",
    "- Save the visualization as comparison_of_clustering_techniques.png.\n",
    "\n",
    "Create two functions:\n",
    "\n",
    "- `apply_clustering_methods(X)` returns the **results** as a dictionary: the keys are the **method names** \"K-Means++\" and \"AHC\" as strings, the values are the **clustering labels** that are returned for each data point in the data set.\n",
    "\n",
    "    `def apply_clustering_methods(X):`\n",
    "          `...`\n",
    "          `return results`\n",
    "  \n",
    "- `plot_clustering_results(X, results)` plots the data points in **X** with two different colors based on their predicted label:\n",
    "  * Use the values in the dictionary **results** retuned by `apply_clustering_methods`.\n",
    "  * Use 'Feature 1' as x-axis label and 'Feature 2' as y-axis label.\n",
    "  * You can combine the figures from the two clustering mrethoids as sub plots. Use:\n",
    "  \n",
    "    `fig, axes = plt.subplots(2, 1, figsize=(18, 12))`\n",
    "\n",
    "    `axes = axes.flatten()`\n",
    "  \n",
    "  * Save the figure named **comparison_of_clustering_techniques.png**.\n",
    "  * Submit the .png file as your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset for clustering problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with half-moon shapes\n",
    "from sklearn.datasets import make_moons\n",
    "X, _ = make_moons(n_samples=100, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4bsfwWbZiOp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def apply_clustering_methods(X):\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_clustering_results(X, results):\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxaqQ98RiKZb",
    "outputId": "73f4e739-65ce-47a4-af5f-0fc7f7513e72"
   },
   "outputs": [],
   "source": [
    "# Try out your code:\n",
    "\n",
    "# Apply clustering methods\n",
    "clustering_results = apply_clustering_methods(X)\n",
    "\n",
    "# Plot and save results\n",
    "plot_clustering_results(X, clustering_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0Ltf0x9iKZb"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqxRRIuKiKZb",
    "outputId": "b3f487ee-510c-4a5d-c01d-0523424c0057"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_5.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def apply_clustering_methods(X):\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_clustering_results(X, results):\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnWVfOb3ZiOp"
   },
   "source": [
    "#### Test 5 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEFhdc_7dGff",
    "outputId": "0028959d-19bb-4beb-e244-ed6abc12f30d"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHlYhXH11dsJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHS2zsUfARtv"
   },
   "source": [
    "# Run all the tests again ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPxwUHEd1dul",
    "outputId": "711bd0ba-a354-4749-8cbc-1a2369e3d470"
   },
   "outputs": [],
   "source": [
    "! ./test/run_test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXV85d2wAVx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-HgeLbAYpq"
   },
   "source": [
    "# Final Exam\n",
    "\n",
    "- The final gexam will be held on **2024-12-11, 6:00 PM (EDT)**.\n",
    "\n",
    "- Make sure that all your programs and output files are in the exact folder as specified in the instructions.\n",
    "\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Execute the cell below to submit your assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwZl5dXMZiOp",
    "outputId": "2b39074e-7488-4143-a5a2-b0541420acd7"
   },
   "outputs": [],
   "source": [
    "! ./submit.sh -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
