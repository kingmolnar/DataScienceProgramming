{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "<p style=\"text-align:right;color:red;font-weight:bold;font-size:16pt;padding-bottom:20px\">Please, copy this notebook before editing!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Set, List, Tuple, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Classification with Decision Trees\n",
    "\n",
    "Review:\n",
    "- Chapter 4 of the ML Book\n",
    "- Scikit-Learn Library https://scikit-learn.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['InsuranceType', 'MaritalStatus', 'OvernightHospitalStay', 'InjuryType']\n",
    "numerical_features = ['NumSoftTissue', 'NumClaimants', 'TotalClaimed', 'IncomeofPolicyHolder', \n",
    "                      'ClaimAmountReceived', 'PercentSoftTissue', 'NumClaims', 'ClaimAmount']\n",
    "target_feature = 'FraudFlag'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Load Data, Split in Train and Test Sets\n",
    "The insurance fraud data are available at `/data/kelleher/MotorInsuranceFraudClaim_clean.csv`\n",
    "\n",
    "In this exercise you will use this dataset to train a decision tree classifier. The first step ofr any supervised machine learning task is to split the data into training and test sets.\n",
    "\n",
    "Write a function `split_data_set` that randomly splits a given dataframe into two frames to a given fraction. E.g. a value of $0.8$ should give 80% of the rows to the first dataframe, and 20% to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your solution to `solution_6_1.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_6_1.py\n",
    "from typing import Set, List, Tuple, Any\n",
    "import pandas as pd\n",
    "\n",
    "def split_data_set(df: pd.DataFrame, frac) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "### your code here\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your code\n",
    "from solution_6_1 import split_data_set\n",
    "\n",
    "data = '/data/kelleher/MotorInsuranceFraudClaim_clean.csv'\n",
    "df = pd.read_csv(data)\n",
    "print(f\"Number of records: {df.shape[0]:,}\")\n",
    "\n",
    "df_train, df_test = split_data_set(df, 0.8)\n",
    "print(f\"Number of rows in Training-Set: {df_train.shape[0]:,}\\nNumber of rows in Test-Set: {df_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 6.1 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 One-Hot-Encoding\n",
    "Many Python ML packages are designed to work with numerical data. We need to convert our categorical features into their on-hot-encoded representation.\n",
    "\n",
    "Use the one-hot-encoder from the Scikit-Learn library\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "Define a function that creates (and fits) a one-hot-encoder for a given dataframe and a list of categorical features that the resulting encoder should transform. The function should return the encoder object that can be used for subsequent transformations.\n",
    "\n",
    "**Note**: Read the documentation and configure the encode so that it:\n",
    "1. handles unknown levels by ignoring them,\n",
    "2. drop the firt the dimenson of the one-hot-encoded vector,\n",
    "3. produces a **dense** output matrix, not a *sparse* matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your solution to `solution_6_2.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_6_2.py\n",
    "from typing import Set, List, Tuple, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def create_one_hot_encoder(df: pd.DataFrame, cat_features: List[str]) -> OneHotEncoder:\n",
    "    ### your code here\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your code\n",
    "from solution_6_2 import create_one_hot_encoder\n",
    "\n",
    "df_train, df_test = split_data_set(df, 0.8)\n",
    "categorical_features = ['InsuranceType', 'MaritalStatus', 'OvernightHospitalStay', 'InjuryType']\n",
    "my_encoder = create_one_hot_encoder(df_train, categorical_features)\n",
    "display(my_encoder.categories_)\n",
    "X_cat = my_encoder.transform(df_train[categorical_features].values)\n",
    "print(X_cat.shape)\n",
    "display(X_cat[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 6.2 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Build Matrices for Descriptive Features and Target\n",
    "\n",
    "Combine the respective matrices of the categorical and numeric features to a matrix $X$ Create a vector $y$ for the target feature.\n",
    "We do this separately for both: training and test sets.\n",
    "\n",
    "Create a function that takes to feature matrices and concatenates them side-by-side. E.g. a matrix with one-hot-encoded categorical features and a matrix with the numerical featurs need to be combined to a single feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your solution to `solution_6_3.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_6_3.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def concat_feature_matrix(mat_left: np.ndarray, mat_right: np.ndarray) -> np.ndarray:\n",
    "    ### your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your code\n",
    "import numpy as np\n",
    "from solution_6_3 import concat_feature_matrix\n",
    "\n",
    "X_train = concat_feature_matrix(\n",
    "    my_encoder.transform(df_train[categorical_features].values),\n",
    "    df_train[numerical_features].values\n",
    ")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 6.3 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train Decision Tree\n",
    "\n",
    "Let's train the model. You will use the `DecisionTreeClassifier` from the scikit-learn package https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "Complete these streps:\n",
    "1. Split the original data into training and test sets with a 70:30 split (training is 70%)\n",
    "2. Create feature matrices $X_{train}$ and $X_{test}$ from the respective data sets. These are matrices (np.ndarray) that have categorical data one-hot-encoded.\n",
    "3. Create vectors $y_{train}$ and $y_{test}$ from the respective target column\n",
    "4. Create a `DecisionTreeClassifier` classifier object and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X_train_cat = # complete this expression\n",
    "X_train_num = # complete this expression\n",
    "X_train = # complete this expression\n",
    "y_train = # complete this expression\n",
    "\n",
    "### Train the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 6.4 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Model Evaluation\n",
    "\n",
    "You want to know how well the model performs on our test data. You prepare the test dataset the same way you prepared the training data: one-hot-encoding, then merge the feature matrices to one. Create a target vector $y_{test}$ with the actual results.\n",
    "\n",
    "Then use the ML model to predict $\\hat{y}$ from the $X_{test}$ data.\n",
    "\n",
    "You can then count how many records were predicted correctly and incorrectly. Create a function that takes the actual target vector and the predicted target vector, and produces counts for:\n",
    "- True Positive (TP): number of records that are actually TRUE and predicted as TRUE\n",
    "- False Negative (FN): number of records that are actually TRUE and predicted as FALSE\n",
    "- False Positive (FP): number of records that are actually FALSE and predicted as TRUE\n",
    "- True Negative (TN): number of records that are actually FALSE and predicted as FALSE\n",
    "\n",
    "Note: In this dataset 0 = False, and 1 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your solution to `solution_6_5.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_6_5.py\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_classification(y_actual: np.ndarray, y_predicted: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    ### your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your code\n",
    "from solution_6_5 import evaluate_classification\n",
    "\n",
    "# 1. Prepare the Test Data\n",
    "X_test_cat = # ....\n",
    "X_test_num = # ....\n",
    "X_test = # ....\n",
    "y_test = # ....\n",
    "\n",
    "# 1. run inference of the classifier on out test set\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "# 2. compare the actual (y_test) with the predicted (y_hat)\n",
    "TP, FN, FP, TN = evaluate_classification(y_test, y_hat)\n",
    "\n",
    "# 3. Review the results. This is called a \"confusion matrix\"\n",
    "print(f\"\"\"\n",
    "              | Predicted\n",
    "              | True  False\n",
    "--------------+------------------\n",
    "Actual True   | {TP:4d}   {FN:4d}\n",
    "       False  | {FN:4d}   {TN:4d}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 6.5 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestingExecute the cell below to run all tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Submission\n",
    "- This homework is due by March 27, 2024, 5:30PM (EDT)\n",
    "- Make sure that all your programs and output files are in the exact folder as specified in the instructions.\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Run the cell below to submit your work.**\n",
    "\n",
    "- You may submit your work multipe times up to the deadline of the assignment.\n",
    "- Please note that any files that you previously submitted will\n",
    "be overwritten by your current files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./submit.sh -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
