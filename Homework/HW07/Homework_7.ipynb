{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "<p style=\"text-align:right;color:red;font-weight:bold;font-size:16pt;padding-bottom:20px\">Please, copy this notebook before editing!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you train multiple regression models on a set of data. You use the model implementation for the scikit-learn package:\n",
    "\n",
    "1. Linear Regression [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "1. Decision Tree Regressor [`sklearn.tree.DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "2. Random Forrest Regressor [`sklearn.ensemble.RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "You also use several tools for pre-processing, namely:\n",
    "1. Encoders from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "2. Imputers sklearn.impute import SimpleImputer\n",
    "3. Scalers sklearn.preprocessing import StandardScaler\n",
    "4. Polynomial features [`sklearn.preprocessing.PolynomialFeatures`]()\n",
    "\n",
    "And finally, you will use implmented methods for:\n",
    "1. Splitting data sets (Train and Test) [`sklearn.model_selection.train_test_split`]()\n",
    "2. Calculate evaluation metrics [`sklearn.metrics.accuracy_score`](), [`sklearn.metrics.mean_squared_error`](), and [`sklearn.metrics.r2_score`]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, r2_score\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data set (drop the `ID` column right away...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd =  pd.read_csv(\"/data/IFI8410/sess09/predict_home_value.csv\") \\\n",
    "    .drop('ID', axis=1) \n",
    "print(f\"Number of records: {df_pd.shape[0]:,}\")\n",
    "display(df_pd.head(5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SALEPRICE` is your target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_pd.SALEPRICE, bins=20)\n",
    "plt.suptitle('Distribution of Sales Price')\n",
    "plt.xlabel('Sales Prices')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test Sets\n",
    "Keep a portion of your data for testing. These are the **un-seen** records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = np.random.random_sample(df_pd.shape[0]) >0.8\n",
    "df_train = df_pd[~test_mask].copy()\n",
    "print(f\"Number of training records: {df_train.shape[0]:,}\")\n",
    "df_test = df_pd[test_mask].copy()\n",
    "print(f\"Number of test records: {df_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the categorical columns \n",
    "categoricalColumns = df_train.select_dtypes(include=[object]).columns\n",
    "\n",
    "print(f\"There are {len(categoricalColumns)} categorical columns: \" )\n",
    "print(categoricalColumns)\n",
    "\n",
    "impute_categorical = SimpleImputer(strategy=\"most_frequent\")\n",
    "onehot_categorical =  OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('impute',impute_categorical),('onehot',onehot_categorical)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the numerical columns \n",
    "numericalColumns = [col for col in df_train.select_dtypes(include=[float,int]).columns \n",
    "                    if col not in ['SALEPRICE']]\n",
    "print(f\"There are {len(numericalColumns)} numerical columns: \" )\n",
    "print(numericalColumns)\n",
    "\n",
    "scaler_numerical = StandardScaler()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[('scale',scaler_numerical)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pre-processor\n",
    "For convenience and integrity you create a pre-processor that performs all the required data transformations. The pre-processor is fitted to the training data. Then, you use the trained pre-processor on the test data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessorForCategoricalColumns = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categoricalColumns)],\n",
    "                                            remainder=\"passthrough\")\n",
    "preprocessorForAllColumns = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categoricalColumns),\n",
    "                  ('num',numerical_transformer,numericalColumns)],\n",
    "                                            remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "#. The transformation happens in the pipeline. Temporarily done here to show what intermediate value looks like\n",
    "\n",
    "preprocessorForCategoricalColumns.fit(df_train)\n",
    "df_train_temp = preprocessorForCategoricalColumns.transform(df_train)\n",
    "df_test_temp = preprocessorForCategoricalColumns.transform(df_test)\n",
    "\n",
    "preprocessorForAllColumns.fit(df_train)\n",
    "df_train_temp_2 = preprocessorForAllColumns.transform(df_train)\n",
    "df_test_temp_2 = preprocessorForAllColumns.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Use this evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(regressor,y_test,y_pred):\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    print(\"Mean squared error: %.2f\"\n",
    "      % mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print('R2 score: %.2f' % r2 )\n",
    "    return (mse, r2)\n",
    "\n",
    "\n",
    "## keep this list to collect results from the various experiments\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Simple Linear Regression\n",
    "\n",
    "There are 13 numerical dependent variables that you can try each of them to train a simple linear regression model. Compare the performance.\n",
    "\n",
    "**Refresher:**\n",
    "\n",
    "This is the most basic form of linear regression in which the variable to be predicted is dependent on only one other variable. This is calculated by using the formula that is generally used in calculating the slope of a line.\n",
    "\n",
    "$y = w_0 + w_1 \\times x_1$\n",
    "\n",
    "In the above equation, $y$ refers to the target variable and $x_1$ refers to the independent variable. w1 refers to the coeeficient that expresses the relationship between $y$ and $x_1$ is it also know as the slope. $w_0$ is the constant cooefficient a.k.a the intercept. It refers to the constant offset that $y$ will always be with respect to the independent variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "### Iterate over each numerical column\n",
    "for ftr in numericalColumns:\n",
    "    print(ftr)\n",
    "    X_train = df_train[ftr].values.reshape(-1, 1)\n",
    "    y_train = df_train['SALEPRICE']\n",
    "    slRegressor = LinearRegression()\n",
    "    \n",
    "    # train model\n",
    "    slRegressor.fit(X_train,y_train)\n",
    "\n",
    "    # inference\n",
    "    X_test = df_test[ftr].values.reshape(-1, 1)\n",
    "    y_actual = df_test['SALEPRICE']\n",
    "    y_pred = slRegressor.predict(X_test)\n",
    "\n",
    "    # evaluate\n",
    "    MSE, R2 = model_metrics(slRegressor,y_actual,y_pred)\n",
    "    results.append({'Model': f'SLR-{ftr}', 'MSE': f\"{MSE:.2f}\", 'R2': f\"{R2:.2f}\"})\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Multiple Linear Regression Model\n",
    "\n",
    "Multiple linear regression is an extension to the simple linear regression. In this setup, the target value is dependant on more than one variable. The number of variables depends on the use case at hand. Usually a subject matter expert is involved in identifying the fields that will contribute towards better predicting the output feature.\n",
    "\n",
    "$y = w_0 + w_1 \\times x_1 + w_2 \\times x_2 + .... + w_n \\times x_n$\n",
    "\n",
    "\n",
    "Since multiple linear regression assumes that output depends on more than one variable, we are assuming that it depends on all the 30 features. Data is split up into training and test sets. As an experiment, you can try to remove a few features and check if the model performs any better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(numericalColumns) + list(categoricalColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_name = 'Multiple Linear Regression'\n",
    "\n",
    "mlRegressor = LinearRegression()\n",
    "\n",
    "mlr_model = Pipeline(steps=[('preprocessorAll',preprocessorForAllColumns),('regressor', mlRegressor)])\n",
    "\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['SALEPRICE']\n",
    "\n",
    "X_test = df_test[features]\n",
    "y_actual = df_test['SALEPRICE']\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "mlr_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = mlr_model.predict(X_test)\n",
    "\n",
    "print(mlRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlr_model.predict(X_test)\n",
    "\n",
    "MSE, R2 = model_metrics(mlRegressor, y_actual, y_pred)\n",
    "results.append({'Model': f'MLR', 'MSE': f\"{MSE:.2f}\", 'R2': f\"{R2:.2f}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Build Polynomial Linear regression model\n",
    "\n",
    "The prediction line generated by simple/linear regression is usually a straight line. In cases when a simple or multiple linear regression does not fit the data point accurately, we use the polynomial linear regression. The following formula is used in the back-end to generate polynomial linear regression.\n",
    "\n",
    "$y = w_0 + w_1 \\times x_1 + w_2 \\times x^2_1 + .... + w_n \\times x^n_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are assuming that output depends on the YEARBUILT and LOTATREA. Data is split up into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['YEARBUILT', 'LOTAREA']]\n",
    "y_train = df_train['SALEPRICE']\n",
    "\n",
    "X_test = df_test[['YEARBUILT', 'LOTAREA']]\n",
    "y_actual = df_test['SALEPRICE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model_name = 'Polynomial Linear Regression'\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=3)\n",
    "plRegressor = LinearRegression()\n",
    "\n",
    "plr_model = Pipeline(steps=[('polyFeature', polynomial_features ),('regressor', plRegressor)])\n",
    "\n",
    "plr_model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(plRegressor)\n",
    "\n",
    "# evaluation\n",
    "y_pred = plr_model.predict(X_test)\n",
    "MSE, R2 = model_metrics(plRegressor, y_actual, y_pred)\n",
    "\n",
    "results.append({'Model': f'PLR-YEARBUILT-LOTAREA', 'MSE': f\"{MSE:.2f}\", 'R2': f\"{R2:.2f}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Decision Tree Regressor\n",
    "\n",
    "The Decision Tree Regressor has multiple hyper-parameters. Experiment with different values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_name = \"Decision Tree Regressor\"\n",
    "\n",
    "\n",
    "X_train = df_train\n",
    "y_train = df_train['SALEPRICE']\n",
    "\n",
    "X_test = df_test\n",
    "y_actual = df_test['SALEPRICE']\n",
    "\n",
    "\n",
    "for max_features in [10, 20, 30]:\n",
    "    decisionTreeRegressor = DecisionTreeRegressor(random_state=0, max_features=max_features)\n",
    "    dtr_model = Pipeline(steps=[('preprocessorAll',preprocessorForAllColumns),\n",
    "                                ('regressor', decisionTreeRegressor)]) \n",
    "\n",
    "    dtr_model.fit(X_train,y_train)\n",
    "\n",
    "    print(f\"Max features = {max_features}\")\n",
    "    y_pred = dtr_model.predict(X_test)\n",
    "    MSE, R2 = model_metrics(decisionTreeRegressor, y_actual, y_pred)\n",
    "\n",
    "    results.append({'Model': f'DecisionTree-{max_features}', 'MSE': f\"{MSE:.2f}\", 'R2': f\"{R2:.2f}\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Random Forest Regression Model\n",
    "\n",
    "Decision tree algorithms are efficient in eliminating columns that don't add value in predicting the output and in some cases, we are even able to see how a prediction was derived by backtracking the tree. However, this algorithm doesn't perform individually when the trees are huge and are hard to interpret. Such models are oftern referred to as weak models. The model performance is however improvised by taking an average of several such decision trees derived from the subsets of the training data. This approach is called the Random Forest Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_name = \"Random Forest Regressor\"\n",
    "\n",
    "X_train = df_train\n",
    "y_train = df_train['SALEPRICE']\n",
    "\n",
    "X_test = df_test\n",
    "y_actual = df_test['SALEPRICE']\n",
    "\n",
    "\n",
    "### Let's experiment with different hyper-parameters\n",
    "for n_estimators in [50, 100]:\n",
    "    for max_depth in [5, 15, 30]:\n",
    "        randomForestRegressor = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, max_depth=max_depth, random_state=0)\n",
    "    \n",
    "        rfr_model = Pipeline(steps=[('preprocessorAll',preprocessorForAllColumns),('regressor', randomForestRegressor)]) \n",
    "    \n",
    "        rfr_model.fit(X_train,y_train)\n",
    "    \n",
    "        y_pred = rfr_model.predict(X_test)\n",
    "        MSE, R2 = model_metrics(randomForestRegressor, y_actual, y_pred)\n",
    "    \n",
    "        results.append({\n",
    "            'Model': f'RF-{n_estimators}-{max_depth}',\n",
    "            'MSE': f\"{MSE:.2f}\",\n",
    "            'R2': f\"{R2:.2f}\"\n",
    "        })\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "You may have created duplicate results. Once everything is working properly, restart the kernel and run everything above. Then run the cell below. You are encouraged to analyse and visualize the performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame.from_records(results) \\\n",
    "    .sort_values('R2', ascending=False)\n",
    "display(result_df.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "There is no automated testing for this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Submission\n",
    "- This homework is due by 2023-04-03, 5:30PM (EDT)\n",
    "- **For this assignment you need to submit your notebook**\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Run the cell below to submit your work.**\n",
    "\n",
    "- You may submit your work multipe times up to the deadline of the assignment.\n",
    "- Please note that any files that you previously submitted will\n",
    "be overwritten by your current files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to submit this notebook\n",
    "#\n",
    "from submit import submit\n",
    "submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
