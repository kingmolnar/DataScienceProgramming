{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvDJJwxUzUCU"
   },
   "source": [
    "\n",
    "\n",
    "# **IFI8410: Programming for Business**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKAsLR0C2DE8"
   },
   "source": [
    "## **Assignment 08**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.173007Z",
     "start_time": "2024-09-30T18:29:20.975777Z"
    },
    "id": "ilcJOwFSvnX-"
   },
   "outputs": [],
   "source": [
    "# Do not change the content of this cell. Execute this cell first, and everytime after you restarted the kernel.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information-Based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiXz48oz2NhW"
   },
   "source": [
    "### 8.1 Load Data, Split in Train and Test Sets\n",
    "\n",
    "Question:\n",
    "\n",
    "You are given a CSV file **Fraud.csv**:\n",
    "\n",
    "- Write a function **split_data_set** that takes in a DataFrame and a fraction **frac** and splits the DataFrame into two separate DataFrames. \n",
    "- The first DataFrame should contain a random selection of **frac** percent of the original rows, and the second DataFrame should contain the remaining rows. \n",
    "- For example, if frac is 0.8, the function should return one DataFrame with 80% of the rows and a second DataFrame with the remaining 20%.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Use **pandas.DataFrame.sample** to select frac percent of the rows for the first DataFrame. \n",
    "- Then, use the complement of this sample for the second DataFrame by selecting rows not in the first DataFrameâ€™s index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.280692Z",
     "start_time": "2024-09-30T18:29:21.186714Z"
    },
    "id": "R7-4vnbIzp-o"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Set, List, Tuple, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def split_data_set(df: pd.DataFrame, ratio: float) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \n",
    "    # Write your code here\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZWGO7ewZiOn",
    "outputId": "ca3f0da9-5831-4cdd-f619-5cd92dbec6eb"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "df = pd.read_csv('/data/IFI8410/sess10/Fraud_data.csv')\n",
    "df_80, df_20 = split_data_set(df, 0.8)\n",
    "print(f\"Number of records: {len(df)}\")\n",
    "print(f\"Number of rows in Training-Set: {len(df_80)}\")\n",
    "print(f\"Number of rows in Test-Set: {len(df_20)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8laWEoeZiOn"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.651471Z",
     "start_time": "2024-09-30T18:29:21.545780Z"
    },
    "id": "SajRmT5AZiOn",
    "outputId": "ccf817cd-02aa-475f-9f02-6eb549d61092"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_1.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def split_data_set(df: pd.DataFrame, ratio: float) -> (pd.DataFrame, pd.DataFrame):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNknpBBrZiOn"
   },
   "source": [
    "#### Test 8.1 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:21.951769Z",
     "start_time": "2024-09-30T18:29:21.720115Z"
    },
    "id": "YusNec-oZiOn",
    "outputId": "d4c014b7-d35f-47eb-ac81-2618e6f277b2"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.022361Z",
     "start_time": "2024-09-30T18:29:22.019044Z"
    },
    "id": "vQl3ctAXZiOn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qfed3KE2Wh9"
   },
   "source": [
    "### 8.2 One-Hot-Encoding\n",
    "\n",
    "Question:\n",
    "\n",
    "Define a function that creates and fits a **One-Hot Encoder** for a given DataFrame and a list of categorical features to be transformed. \n",
    "\n",
    "The function should return an encoder object that can be re-used for future transformations of similar data.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Handle unknown categories by ignoring them.\n",
    "- Drop the first level in each one-hot-encoded vector to reduce dimensionality.\n",
    "- Produce a dense output matrix (not sparse).\n",
    "\n",
    "Hint\n",
    "- To implement this, use the **OneHotEncoder** from **sklearn.preprocessing**. \n",
    "- Ignore unknown categories during transformation.\n",
    "- Drop the first column of each one-hot-encoded feature to avoid collinearity.\n",
    "- Set the output to a dense array instead of a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.226699Z",
     "start_time": "2024-09-30T18:29:22.124362Z"
    },
    "id": "4cjZCE_Q2hN1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def create_one_hot_encoder(df: pd.DataFrame, categorical_features: list) -> OneHotEncoder:\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8_Sh6VFZiOo",
    "outputId": "d5df8993-ea64-45dc-e5ec-d6c1b3fd7769"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('/data/IFI8410/sess10/Fraud_data.csv')\n",
    "\n",
    "# Define the list of categorical features to encode\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "\n",
    "# Create and fit the one-hot encoder\n",
    "encoder = create_one_hot_encoder(df, categorical_features)\n",
    "\n",
    "# Display categories in the encoder to confirm it was fitted correctly\n",
    "print(\"Categories in encoder:\", encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlsMD8zXZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.551198Z",
     "start_time": "2024-09-30T18:29:22.451243Z"
    },
    "id": "I3WoLmN_ZiOo",
    "outputId": "c46cec1a-bc0a-47df-c821-9ee204b46b94"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_2.py\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def create_one_hot_encoder(df: pd.DataFrame, categorical_features: list) -> OneHotEncoder:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6Zay9KIZiOo"
   },
   "source": [
    "#### Test 8.2 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:22.844763Z",
     "start_time": "2024-09-30T18:29:22.606809Z"
    },
    "id": "50Vqcn6oZiOo",
    "outputId": "0e05b742-a333-4d5e-8066-720ecf0be8d5"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UguNN8jDZiOo"
   },
   "source": [
    "### 8.3 Prediction and Accuracy for Decision Tree Model\n",
    "\n",
    "Question:\n",
    "\n",
    "- Train a **Decision Tree Model** on a fraud dataset:\n",
    "\n",
    "- Write a function that processes the **Fraud_data.csv** dataset and trains a **Decision Tree classifier** to predict fraud. \n",
    "\n",
    "Your task is to:\n",
    "\n",
    "- Load and preprocess the data by one-hot encoding categorical columns.\n",
    "- Split the dataset into training and test sets with a 70:30 ratio.\n",
    "- Train a **DecisionTreeClassifier** model using the training data.\n",
    "- Evaluate the model using accuracy, precision, recall, and F1-score on the test set.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use a `OneHotEncoder` to encode categorical features, ensuring unknown levels are ignored. \n",
    "- The first category is dropped, and dense output is returned.\n",
    "- Return the calculated metrics **accuracy, precision, recall, F1-score** on the test set in the function output.\n",
    "\n",
    "Hint :\n",
    "\n",
    "- Use as target feature **FraudFound_P**.\n",
    "  \n",
    "- Splitting the Data into Training and Test Data: Use `train_test_split` with a 70% train and 30% test split.\n",
    "\n",
    "- One-Hot Encoding of Categorical Features: Apply `OneHotEncoder` on the categorical columns, setting parameters to ignore unknown values, drop the first level, and return a dense matrix.\n",
    "\n",
    "- Numeric Features: Make sure that all your numeric features are actually numeric and that you fill missing values. You can e.g. achieve this by transforming the numeric features (i.e. the non-categorical features) via applying the method `.apply(pd.to_numeric, errors='coerce').fillna(0)` to the numeric features in your dataframe.\n",
    "\n",
    "- Model Training: Use `DecisionTreeClassifier` to train on the training data.\n",
    "\n",
    "- Metrics Calculation: Use scikit-learnâ€™s `accuracy_score`, `precision_score`, `recall_score`, and `f1_score` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTVwGNd_ZiOo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_decision_tree(df: pd.DataFrame, categorical_features: list) -> tuple:\n",
    "    \n",
    "    # Write your code here\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSGIa-OUZiOo",
    "outputId": "a44ea5b6-d55f-42d6-c7cb-aaea3442ca8e"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Load the dataset\n",
    "file_path = '/data/IFI8410/sess10/Fraud_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "\n",
    "# Run the training and evaluation function\n",
    "process_and_train_decision_tree(df, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_In_ItuZiOo"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faaGepf2ZiOp",
    "outputId": "e15e8751-6a28-4819-9c57-8dbfbeb63287"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_3.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_decision_tree(df: pd.DataFrame, categorical_features: list) -> tuple:\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rjDbFLWZiOp"
   },
   "source": [
    "#### Test 8.3 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBnZK_-EZiOp",
    "outputId": "b12bd2c8-50ec-4171-8ede-f0ef61cd78df"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Prediction and Accuracy for XGBOOST Model\n",
    "\n",
    "Question\n",
    "\n",
    "- Train a Decision Tree Model on Fraud Data.\n",
    "\n",
    "- Write a function that processes the Fraud_data.csv dataset and trains an **XGBOOST** classification model to predict fraud. \n",
    "\n",
    "Your task is to:\n",
    "\n",
    "- Load and preprocess the data by one-hot encoding categorical columns.\n",
    "- Split the dataset into training and test sets with a 70:30 ratio.\n",
    "- Train a **XGBOOST classifier** model using the training data.\n",
    "- Evaluate the model using **accuracy, precision, recall, and F1-score** on the test set.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Use as target feature **FraudFound_P**.\n",
    "- Use a `OneHotEncoder` to encode categorical features, ensuring unknown levels are ignored. \n",
    "- The first category is dropped, and dense output is returned.\n",
    "- Again, make sure that all your numeric features are actually numeric and that you fill missing values. You can e.g. achieve this by transforming the numeric features via applying the method `.apply(pd.to_numeric, errors='coerce').fillna(0)` to the numeric features in your dataframe. See also Problem 8.3.\n",
    "- Return the calculated metrics **accuracy, precision, recall, F1-score** on the test set in the function output.\n",
    "\n",
    "Hint:\n",
    "\n",
    "- Use `XGBClassifier` from scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQkYU4IGZiOp",
    "outputId": "f67000ea-c0d9-405d-98e2-a3b88a01aa71"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_path = '/data/IFI8410/sess10/Fraud_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "\n",
    "process_and_train_xgboost(df, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_8_4.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_xgboost(df: pd.DataFrame, categorical_features: list) -> tuple:\n",
    "    \n",
    "    # Write your code here\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 8.4 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJRnlEBNZiOp",
    "outputId": "8015fe96-12bc-4666-f202-699c2a231475"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def process_and_train_xgboost(df: pd.DataFrame, categorical_features: list) -> tuple:\n",
    "    \n",
    "    # Write your code here\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! test/run_test.sh 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3F103HXZiOp"
   },
   "source": [
    "### 8.5 Model Evaluation\n",
    "\n",
    "Question:\n",
    "\n",
    "- Write a function `evaluate_classification` to evaluate the predictions of a decision tree model on a fraud detection dataset. \n",
    "\n",
    "- This function takes as input the vector of actual labels **y_actual** and the vector of predicted labels **y_pred**.\n",
    "\n",
    "- This function should count the number of **True Positives, False Negatives, False Positives,** and **True Negatives** and then display the results in a summary table.\n",
    "\n",
    "Hint:\n",
    "\n",
    "Use `np.sum` and logical conditions to count occurrences of each type:\n",
    "\n",
    "- **True Positive:** when the actual and predicted values are both True\n",
    "- **False Negative:** when the actual value is True and predicted is False\n",
    "- **False Positive:** when the actual value is False and predicted is True\n",
    "- **True Negative:** when both are False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the classification model (DO NOT MODIFY THIS CODE HERE!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4bsfwWbZiOp",
    "outputId": "f56c929a-d6e9-422b-b81f-7ed7df539763",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "file_path = '/data/IFI8410/sess10/Fraud_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define features\n",
    "categorical_features = [\n",
    "    'Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'Fault',\n",
    "    'PolicyType', 'VehicleCategory', 'PoliceReportFiled',\n",
    "    'WitnessPresent', 'BasePolicy'\n",
    "]\n",
    "target_feature = 'FraudFound_P'\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)\n",
    "X_cat = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "# Enhanced cleaning function to handle ranges, units, and 'none' values\n",
    "def clean_numerical_data(value):\n",
    "    if isinstance(value, str):\n",
    "        # Convert ranges to midpoints\n",
    "        if 'to' in value:\n",
    "            start, end = map(int, value.split(' to '))\n",
    "            return (start + end) / 2\n",
    "        # Extract numbers from text with units like \"5 years\" or \"1 vehicle\"\n",
    "        elif any(char.isdigit() for char in value):\n",
    "            return int(''.join(filter(str.isdigit, value)))  # Extracts numeric part only\n",
    "        # Handle cases like 'none' or other strings by returning NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "    return value  # Return value if already numeric\n",
    "\n",
    "# Apply cleaning function to numerical data\n",
    "df_num = df.drop(columns=[target_feature] + categorical_features)\n",
    "df_num = df_num.applymap(clean_numerical_data)\n",
    "\n",
    "# Handle NaNs by replacing them with the column mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_num = imputer.fit_transform(df_num)\n",
    "\n",
    "# Prepare feature matrix and target vector\n",
    "X = np.hstack([X_cat, X_num])\n",
    "y = df[target_feature].values\n",
    "\n",
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your evaluation function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(y_actual, y_pred):\n",
    "\n",
    "    # Write your code here:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your code here:\n",
    "TP, FN, FP, TN = evaluate_classification(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"\"\"\n",
    "              | Predicted\n",
    "              | True  False\n",
    "--------------+------------------\n",
    "Actual True   | {TP:4d}   {FN:4d}\n",
    "       False  | {FP:4d}   {TN:4d}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile solution_8_5.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_classification(y_actual, y_pred):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnWVfOb3ZiOp"
   },
   "source": [
    "#### Test 8.5 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEFhdc_7dGff"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdIRs7fPdory"
   },
   "source": [
    "## Similarity-Based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM15K91DdwdF"
   },
   "source": [
    "### 8.6: Implement a Robust KNN Classifier\n",
    "\n",
    "You are given a dataset with several features and a target column. Your task is to implement a **KNN classifier** that includes necessary preprocessing steps to handle both categorical and numerical data. \n",
    "\n",
    "The aim is to build a reliable KNN model using **k=2** with optimized preprocessing.\n",
    "\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "Implement the function `knn_classifier` that will:\n",
    "\n",
    "- Take a dataset (as a DataFrame), a list of feature columns (**X**), and a target column (**y**) as input.\n",
    "\n",
    "- Apply preprocessing to handle both categorical and numerical features:\n",
    "\n",
    "- Use **One-Hot Encoding** for categorical features.\n",
    "\n",
    "- Apply **Standard Scaling** to numerical features.\n",
    "\n",
    "- Transform string labels in target column **y** into 0 and 1 as labels via **Label Encoding** if necessary.\n",
    "\n",
    "- Train a KNN classifier using k=2.\n",
    "\n",
    "\n",
    "Evaluate the classifier using the testing set and provide the following:\n",
    "\n",
    "- The accuracy of the classifier.\n",
    "\n",
    "- A classification report that includes metrics like precision, recall, and F1-score.\n",
    "\n",
    "- Return the **accuracy** and the **classification report**.\n",
    "\n",
    "\n",
    "**Hint:**\n",
    "- Use as feature columns **'WeekOfMonth', 'AccidentArea', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'VehicleCategory', 'Deductible', 'DriverRating', 'PoliceReportFiled'**.\n",
    "- Use as target columnn **'BasePolicy'**.\n",
    "- Use the `OneHotEncoder` from **sklearn.preprocessing** for categorical variables.\n",
    "- Use `StandardScaler` to scale numerical features.\n",
    "- Use `LabelEncoder` for **Label Encoding** of target feature **y**.\n",
    "- Use `KNeighborsClassifier` for the kNN classifier model.\n",
    "- Utilize `Pipeline` and `ColumnTransformer` to streamline the preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4yCsk2wdG34"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def knn_classifier(data, feature_columns, target_column, k=2):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiJsKNBwdG6M",
    "outputId": "d5c0aa76-eb86-49be-8064-b5a00e8b60bc"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "# Load the dataset\n",
    "df6 = pd.read_csv('/data/IFI8410/sess10/reduced_fraud_oracle.csv')\n",
    "\n",
    "# Define the features and target\n",
    "feature_columns = ['WeekOfMonth', 'AccidentArea', 'Sex', 'MaritalStatus', 'Age', 'Fault', 'VehicleCategory', 'Deductible', 'DriverRating', 'PoliceReportFiled']\n",
    "target_column = 'BasePolicy'\n",
    "\n",
    "# Call the classifier function\n",
    "accuracy, report = knn_classifier(df6, feature_columns, target_column)\n",
    "\n",
    "# Display the results\n",
    "print(\"Accuracy of KNN Classifier (k=2):\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWv_PDv6iy02"
   },
   "source": [
    "#### Save your solution to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nH2NdV4dG_K",
    "outputId": "c630ddca-cbb3-4775-d509-572c9b331b8c"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_6.py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def knn_classifier(data, feature_columns, target_column, k=2):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFKL7uenjLbo"
   },
   "source": [
    "#### Test 8.6 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnQ-hbhahZ6P",
    "outputId": "24d2580a-965d-4d3d-879d-10048da282ef"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB6lkg-6hZ-b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWLhOGM7n2C6"
   },
   "source": [
    "### 8.7 KNN Classifier for Insurance Use Case\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "You are given a dataset that contains insurance information, including features related to accidents and claims. \n",
    "\n",
    "Create the following function `knn_fraud_detection` that should:\n",
    "\n",
    "- Implement a `KNN classifier` with **k=3** to predict whether a claim is fraudulent (**FraudFound_P**).\n",
    "\n",
    "- Use the entire dataset provided, but an example illustration uses the first 5 rows for clarity.\n",
    "\n",
    "- Use relevant features **VehiclePrice, Age, DriverRating, VehicleCategory, PastNumberOfClaims** to train the model.\n",
    "\n",
    "- Evaluate the classifier on the entire dataset and return its accuracy and a classification report.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Select as feature columns **VehiclePrice, Age, DriverRating, VehicleCategory, PastNumberOfClaims**.\n",
    "  \n",
    "- Select as target column **FraudFound_P**.\n",
    "\n",
    "- Handle missing or categorical data appropriately before training.\n",
    "\n",
    "- Consider encoding categorical features like **VehiclePrice** and **VehicleCategory** using `LabelEncoder`.\n",
    "\n",
    "- Use again `KNeighborsClassifier` for the kNN classifier model.\n",
    "\n",
    "- Use `train_test_split` to split the dataset into training and testing sets.\n",
    "\n",
    "- Use metrics like `accuracy_score` and `classification_report` to assess the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBWoG4Z_haA-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_fraud_detection(data):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ul4BovHVhaDJ",
    "outputId": "c6b0bcf1-1df3-41f5-8d1c-c2b113733096"
   },
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/data/IFI8410/sess10/reduced_fraud_oracle.csv')\n",
    "\n",
    "# Call the function using the full dataset\n",
    "accuracy, report = knn_fraud_detection(df)\n",
    "\n",
    "# Display the full dataset results\n",
    "print(\"\\nAccuracy of KNN Fraud Detection (k=3) - Data:\", accuracy)\n",
    "print(\"Classification Report for Data:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXzN_IKAv-bW"
   },
   "source": [
    "#### Save your solution to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpi7k_yVhaFs",
    "outputId": "f3752155-a32d-438d-e621-7b9d6614eda0"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_7.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_fraud_detection(data):\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8XMf9CPwJKh"
   },
   "source": [
    "#### Test 8.7 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5d0XhichaIB",
    "outputId": "13da9dbb-1ace-4a92-b84a-955d32a797c7"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPzRrWaRhaM4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC_NNbXt0QTy"
   },
   "source": [
    "### 8.8 Visualize KNN Classifier Results with Confusion Matrix\n",
    "\n",
    "In this problem, you'll implement a function to visualize the performance of a **KNN classifier** using a **confusion matrix**. \n",
    "\n",
    "The plot should clearly show the number of **True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN)**.\n",
    "\n",
    "The KNN model should be trained on a dataset, and you will use a confusion matrix to show how well the classifier performs.\n",
    "\n",
    "The function should take the trained KNN classifier's predictions and visualize these metrics using a heatmap.\n",
    "\n",
    "\n",
    "**Problem Description**:\n",
    "\n",
    "You are given a dataset with features and target labels for fraud detection.\n",
    "\n",
    "Implement the `knn_plot_confusion_matrix` function that:\n",
    "\n",
    "- Trains a KNN classifier with k=3.\n",
    "\n",
    "- Plots a confusion matrix that shows the counts of TP, TN, FP, and FN.\n",
    "\n",
    "- Uses the **seaborn** and **matplotlib** libraries for visualization.\n",
    "\n",
    "- Inputs to the function are the DataFrame **data**, the feature columns **feature_columns** (as list of column names) and the target column **target_column**.\n",
    "\n",
    "\n",
    "**Function Requirements**:\n",
    "\n",
    "- The function should train the KNN classifier.\n",
    "\n",
    "- Generate predictions on the test set.\n",
    "\n",
    "- Plot a confusion matrix using `seaborn.heatmap`.\n",
    "\n",
    "- Ensure that the plot is annotated with counts for TP, TN, FP, and FN.\n",
    "\n",
    "- Add a title 'Confusion Matrix of KNN Classifier (k=3)'. Add axes labels 'Predicted Labels' for x-axis and 'Actual Labels' for y-axis.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Use the `confusion_matrix` method from scikit-learn.\n",
    "- Look at problem 8.7 to create a similar setup for your model training and prediction.\n",
    "- You can use the same DataFrame and feature colunns and target column as in 8.7 to try out your function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bWcyKZ-haPR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def knn_plot_confusion_matrix(data, feature_columns, target_column):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Ll3KdmcMhaRt",
    "outputId": "3ead33ef-f2f0-462d-ee82-8456eb3a1a88"
   },
   "outputs": [],
   "source": [
    "# Try out your function:\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/data/IFI8410/sess10/reduced_fraud_oracle.csv')\n",
    "feature_columns = ['VehiclePrice', 'Age', 'DriverRating', 'VehicleCategory', 'PastNumberOfClaims']\n",
    "target_column = 'FraudFound_P'\n",
    "\n",
    "# Call the visualization function\n",
    "knn_plot_confusion_matrix(df, feature_columns, target_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVwrPB_51FfE"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxLMaMR8haUA",
    "outputId": "caa74afa-417e-4073-a011-84b57e9fffcb"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_8.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def knn_plot_confusion_matrix(data, feature_columns, target_column):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZmM0R1u1Z8E"
   },
   "source": [
    "#### Test 8.8 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqCwclf01c00",
    "outputId": "7654f922-e11b-4646-9113-12d053d1c2f5"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DS2hVN7t1c68"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECB7Q4VP1EI6"
   },
   "source": [
    "### 8.9 Implement KNN for Fraud Probability Prediction\n",
    "\n",
    "In this problem, you will use a **KNN classifier** to predict the probability that a transaction is fraudulent.\n",
    " \n",
    "Instead of simply predicting a binary outcome (fraud or no fraud), your task is to output the probability of fraud for each transaction. \n",
    "\n",
    "This involves using the `predict_proba` method in **sklearn's** `KNeighborsClassifier`.\n",
    "\n",
    "\n",
    "**Problem Description**:\n",
    "\n",
    "- You are given a dataset containing transactions, some of which are fraudulent.\n",
    "\n",
    "- Train a KNN classifier with k=5 to predict whether a transaction is fraudulent.\n",
    "\n",
    "- Use the model to output the probability that each transaction is fraudulent.\n",
    "\n",
    "- Implement a function to calculate the predicted probabilities and display the results.\n",
    "\n",
    "- Implement a `knn_fraud_probability` function that trains a KNN classifier using **k=5**.\n",
    "\n",
    "- Output the probability that a transaction is fraudulent using the method `predict_proba`.\n",
    "\n",
    "- Return a DataFrame that contains exactly the top 5 transactions with the highest probability of being fraudulent sorted in descending order. The fraud probabilities should be contained in a column named **Fraud_Probability** with its values sorted in descending order. The returned DataFrame should include an additional column named **Actual_Label** .\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Select as feature columns **VehiclePrice, Age, DriverRating, VehicleCategory, PastNumberOfClaims**.\n",
    "  \n",
    "- Select as target column **FraudFound_P**.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCXMXZiS1c8l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "def knn_fraud_probability(data):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfPdVm3N1c-0",
    "outputId": "8fdc996f-2be1-4627-c142-df4f8bdc677b"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df2 = pd.read_csv('//data/IFI8410/sess10/reduced_fraud_oracle.csv')\n",
    "\n",
    "# Call the function\n",
    "fraud_probabilities = knn_fraud_probability(df2)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nTop 5 Transactions with Highest Fraud Probability:\")\n",
    "print(fraud_probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NShYToOQ4tMS"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnxAz9aw1dif",
    "outputId": "edbb0bd5-efef-4941-f663-42fd1bbdbe3d"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_9.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "def knn_fraud_probability(data):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etETMjWN4tTZ"
   },
   "source": [
    "#### Test 8.9 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSNd5p9_1dkz",
    "outputId": "0caf7434-b613-47ba-f664-715cb25eec64"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV8PVDYY1dpo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSuyjSLe6CGW"
   },
   "source": [
    "### 8.10 Implement a Hybrid Model using XGBoost and Random Forest for Fraud Detection\n",
    "\n",
    "**Problem Description**:\n",
    "\n",
    "- You are given a dataset containing transaction data, some of which are fraudulent.\n",
    "\n",
    "- Implement a function called `hybrid_fraud_detection` that:\n",
    "\n",
    "- Trains an **XGBoost model** and a **Random Forest model** to predict fraudulent transactions using the same dataset.\n",
    "\n",
    "- Implements a voting mechanism that combines the predictions from both models.\n",
    "\n",
    "- Outputs the **accuracy** and **classification report** of the combined model.\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Use the `VotingClassifier` function from **scikit-learn** via a function call `VotingClassifier(estimators=[('xgb', xgb), ('rf', rf)], voting='soft')` to combine both models.\n",
    "- Then perform model training and prediction with the combined model similar to problem 8.7.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jf0Cjd-5gUu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def hybrid_fraud_detection(data):\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPUuio0x5gW5",
    "outputId": "2db7eb69-8988-4fca-d039-b11e563e4f3f"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df3 = pd.read_csv('/data/IFI8410/sess10/reduced_fraud_oracle.csv')\n",
    "\n",
    "# Call the hybrid model function\n",
    "accuracy, report = hybrid_fraud_detection(df3)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nAccuracy of Hybrid Fraud Detection Model (XGBoost + Random Forest):\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FD_oDUd6rqh"
   },
   "source": [
    "#### Save your solution to a file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cCiOg055gaH",
    "outputId": "afe29dcf-17db-4dde-c60a-bdad89cd50c8"
   },
   "outputs": [],
   "source": [
    "%%writefile solution_8_10.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def hybrid_fraud_detection(data):\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn3b2ioS65Gm"
   },
   "source": [
    "#### Test 8.10 Execute the cell below to test your solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0V4BGCQv5Rzl",
    "outputId": "d1eaa46f-c5a9-4a6d-e100-641c2880cbc1"
   },
   "outputs": [],
   "source": [
    "! test/run_test.sh 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHlYhXH11dsJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHS2zsUfARtv"
   },
   "source": [
    "# Run all the tests again ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPxwUHEd1dul"
   },
   "outputs": [],
   "source": [
    "! ./test/run_test.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXV85d2wAVx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml-HgeLbAYpq"
   },
   "source": [
    "#Homework Submission\n",
    "\n",
    "- This homework is due by **2024-11-06, 6:00 PM (EDT)**.\n",
    "\n",
    "- Make sure that all your programs and output files are in the exact folder as specified in the instructions.\n",
    "\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Execute the cell below to submit your assignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwZl5dXMZiOp",
    "outputId": "2b39074e-7488-4143-a5a2-b0541420acd7"
   },
   "outputs": [],
   "source": [
    "! ./submit.sh -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKrOeGexZiOp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKcp_rsZZiOq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
