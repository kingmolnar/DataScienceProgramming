{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering data using scikit-learn\n",
    "\n",
    "<p style=\"text-align:right;color:red;font-weight:bold;font-size:16pt;padding-bottom:20px\">Please, copy this notebook before editing!</p>\n",
    "\n",
    "\n",
    "## Instructions\n",
    " 1. Follow this notebook and execute everyt step\n",
    " 2. Be curious: look at some of the data structures and variables that are generated along the way. Seeing what goes into a function and what is returned helps understaning how the function works.\n",
    " 3. Be brave: make changes...what happens?\n",
    " 4. Submit! Run the cell at the end to submit your notebook. You will be graded on completing the steps.\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Clustering algorithms allow you to automatically find ways to group multidimentional data into clusters.\n",
    "\n",
    "In this notebook, we'll use scikit-learn to predict clusters. \n",
    "scikit-learn provides implementations of many clustering algorithms.\n",
    "As we experiment with each clustering algorithm, you'll see some of the advantages and drawbacks of each one.\n",
    "The following algorithms are demonstrated in this notebook:\n",
    "\n",
    "* k-means\n",
    "* Mean shift\n",
    "* DBSCAN\n",
    "* Agglomerative clustering\n",
    "\n",
    "To help visualize what we are doing, we'll use 3D charts to show how the clustering looks (with 3 selected dimensions) with two of the most popular Python visualization tools:\n",
    "\n",
    "* matplotlib enhanced with seaborn styling and animation\n",
    "* Plotly for a more interactive view (e.g., zoom and rotate a 3D chart with your mouse)\n",
    "\n",
    "Finally, because we are playing with the same data that we use for supervised learning, we will look at how our unsupervised creation of clusters might create customer groups that have similar attributes. That is, will our customer groups happen to indicate a likely risk of churn. Please keep in mind that the point of this exercise is not to create a churn classifier, we are just using that to see how these customer clusters might be interesting.\n",
    "\n",
    "Source: <https://github.com/IBM/ml-learning-path-assets/blob/master/notebooks/clustering_with_scikit-learn.ipynb>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import the python modules that we need in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import sleep\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "from matplotlib import lines\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the customer and trading activity data\n",
    "\n",
    "Use the cell below to load the merged_customers.csv file into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/IFI8410/homework8/mergedcustomers.csv\")\n",
    "print(f\"Number of records: {df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the customer data\n",
    "\n",
    "Remove the CHURNRISK column. We don't want to use that label for clustering, but we will save it to try some external evaluation of our clusters later.\n",
    "Select just a few numeric columns as features for our customer clusterer demos -- including gains minus losses combined into a single PROFIT_YTD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CHURNRISK label column for later.\n",
    "known_risk = df['CHURNRISK']\n",
    "\n",
    "# Combine gains - losses into a profit column,\n",
    "# and select a some of the numeric trader data to use for our customer clustering example.\n",
    "keep_columns = ['AGE', 'TOTALUNITSTRADED', 'DAYSSINCELASTTRADE', 'DAYSSINCELASTLOGIN', 'PROFIT_YTD']\n",
    "\n",
    "df_churn = df.assign(PROFIT_YTD=df.apply(lambda row: row.NETREALIZEDGAINS_YTD - row.NETREALIZEDLOSSES_YTD, axis=1).values)[keep_columns]\n",
    "\n",
    "# Pick 3 features to use later in 3D charts\n",
    "x_name = 'AGE'\n",
    "y_name = 'PROFIT_YTD'\n",
    "z_name = 'DAYSSINCELASTTRADE'\n",
    "\n",
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the scikit-learn datasets\n",
    "\n",
    "Using the customer data is not the most obvious clustering experiment.\n",
    "scikit-learn make_blobs() and make_moons() will give us some better examples for certain algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 features even though we generally only chart 3 (these are nice multidemensional, spherical clusters)\n",
    "n_features = 10\n",
    "n_samples = 1000\n",
    "random_state = 100\n",
    "\n",
    "# blobs is our generated data set.  blob_labels is the expected blob cluster membership.\n",
    "blobs, blob_labels = make_blobs(n_samples=n_samples, n_features=n_features, random_state=random_state)\n",
    "\n",
    "# Put the data set in a DataFrame and give it some columns names.\n",
    "blobs_df = pd.DataFrame(blobs, columns=['X', 'Y', 'Z', 'A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "blobs_df['CLUSTER'] = blob_labels\n",
    "\n",
    "# 2-dimensional moons dataset to show where some algorithms excel.\n",
    "moons, moon_labels = make_moons(n_samples=n_samples, noise=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup visualization\n",
    "\n",
    "Configure seaborn to enhance our matplotlib charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "plt.rcParams['figure.figsize'] = [8, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions that will be used repeatedly for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D matplotlib (plus seaborn) charting with some data prep and optional center points\n",
    "def show_scatter_3d(df, x_name, y_name, z_name, predicted=None, centers=None,\n",
    "                    marker='o', cmap=None, edgecolors=None, alpha=0.3,\n",
    "                    elev=25, azim=10, show_colorbar=True,\n",
    "                    xlim3d=None, ylim3d=None, zlim3d=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    x_index = df.columns.get_loc(x_name)\n",
    "    y_index = df.columns.get_loc(y_name)\n",
    "    z_index = df.columns.get_loc(z_name)\n",
    "    \n",
    "    x = df[x_name]\n",
    "    y = df[y_name]\n",
    "    z = df[z_name]\n",
    "\n",
    "    if centers is not None:\n",
    "        spot_size=15  # Smaller spots make X more visible\n",
    "        for center in centers:\n",
    "            if center is not None:\n",
    "                ax.scatter(center[x_index], center[y_index], center[z_index], marker=\"X\", s=500, color='red')\n",
    "    else:\n",
    "        spot_size=30\n",
    "\n",
    "    # Pass in cmap if necessary, else get a right-sized list here\n",
    "    if not cmap:\n",
    "        cmap = ListedColormap(sns.color_palette(\"Set2\",len(set(predicted))))\n",
    "    \n",
    "    chart = ax.scatter(x, y, z, c=predicted, marker=marker, edgecolors=edgecolors, cmap=cmap, s=spot_size, alpha=alpha)\n",
    "    \n",
    "    # Add axis labels\n",
    "    ax.set_xlabel(x_name)\n",
    "    ax.set_ylabel(y_name)\n",
    "    ax.set_zlabel(z_name)\n",
    "    \n",
    "    # Optionally, set the axis limits:\n",
    "    if xlim3d:\n",
    "        ax.set_xlim3d(xlim3d)\n",
    "    if ylim3d:\n",
    "        ax.set_ylim3d(ylim3d)\n",
    "    if zlim3d:\n",
    "        ax.set_zlim3d(zlim3d)\n",
    "\n",
    "    # Make room for axis titles\n",
    "    plt.subplots_adjust(bottom=1, top=3, left=0, right=2)\n",
    "    \n",
    "    # Chart rotation\n",
    "    ax.view_init(elev, azim)\n",
    "    \n",
    "    if show_colorbar:\n",
    "        fig.colorbar(chart, ticks=list(set(predicted)))\n",
    "    \n",
    "    return fig, ax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RdYlBu = plt.get_cmap('RdYlBu')  # colormap for moons\n",
    "\n",
    "def show_scatter_moons(data, prediction, centers=[]):\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=prediction, cmap=RdYlBu, alpha=0.5);\n",
    "    for center in centers:\n",
    "        plt.scatter(center[0], center[1], marker=\"X\", s=300, color='red')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly 3D scatter chart is almost a one-liner, but use this function to keep the params in one place\n",
    "def plotly_scatter_3d(df, x, y, z, color=None):\n",
    "    fig = px.scatter_3d(df, x=x, y=y, z=z, color=color,\n",
    "                    opacity=0.2, template='plotly_dark', color_continuous_scale=px.colors.qualitative.Set1)\n",
    "    fig.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a stacked bar chart for an external evaluation of the churn cluster vs known churn risk\n",
    "\n",
    "# Map the risk values to sortables (and still OK for the legend)\n",
    "risk_map = {'High': '2: High', 'Medium': '1: Medium', 'Low': '0: Low'}\n",
    "    \n",
    "# Reusable chart to see if our clusters might help with churn risk prediction\n",
    "def show_risk_by_cluster(data, risk):\n",
    "    \n",
    "    # Create DataFrame with predicted CLUSTER ID\n",
    "    data_df = pd.DataFrame(data=data, columns=['CLUSTER'])\n",
    "    \n",
    "    # Add CHURN_RISK using sortable values\n",
    "    data_df['CHURN_RISK'] = risk.map(risk_map)\n",
    "    \n",
    "    # Group by and count to get count of Hi/Med/Low in each cluster\n",
    "    grouped_data = data_df.groupby(['CLUSTER', 'CHURN_RISK']).size().to_frame().reset_index()\n",
    "    \n",
    "    # Pivot for charting\n",
    "    pivot = grouped_data.pivot(index='CLUSTER', columns='CHURN_RISK', values=0).fillna(0)\n",
    "    \n",
    "    # Sort to show descending High and then ascending Low counts\n",
    "    pivot = pivot.reindex(pivot.sort_values(by=['2: High', '0: Low'], ascending=[False, True]).index)\n",
    "\n",
    "    # Plot the sorted stacked bar chart\n",
    "    pivot.plot(kind='bar', stacked=True, color='gbr')\n",
    "\n",
    "    # Put the legend on the side    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the input data sets\n",
    "\n",
    "scikit-learn's make_blobs() generated hyperspheres and also returned a cluster membership (`y`).\n",
    "Here we can visualize (3 selected features of) the data and use color to show the cluster membership. \n",
    "Later, we'll ignore the cluster membership, but try to \"predict\" clusters using various algorthms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_3d(blobs_df, 'X', 'Y', 'Z', predicted=blob_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the same thing we just showed with matplotlib, but now we have tooltips and we can zoom and rotate.\n",
    "# Rotating the chart can be very helpful when clusters are overlapping in 3-dimensional space.\n",
    "plotly_scatter_3d(blobs_df, 'X', 'Y', 'Z', color='CLUSTER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The moons data set is only two-dimensional but demonstrates some cluster algorithm differences.\n",
    "\n",
    "show_scatter_moons(moons, moon_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer data set is more like real world data. To visualize that we pick three features that we think are significant. We haven't predicted clusters yet, so we'll just show the color of the CHURNRISK label that we saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did not use k-means yet, let's just use the labels for color\n",
    "label_colors = known_risk.map({'High': 'r', 'Medium': 'b', 'Low': 'g'})\n",
    "\n",
    "show_scatter_3d(df_churn, x_name, y_name, z_name, predicted=label_colors, show_colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning with clustering\n",
    "\n",
    "In general, for each algorthm, we will:\n",
    "\n",
    "* Construct an instance with parameters and/or defaults for the clustering algorithm\n",
    "* Call fit_predict() to predict cluster membership for our dataset using that instance\n",
    "* Use charts to demonstrate the results\n",
    "* Evaluate the results\n",
    "\n",
    "### k-means\n",
    "\n",
    "First, we look at k-means clustering.\n",
    "\n",
    "* For k-means, you have to specify the number of clusters you want. We'll start with 3, but you can run this cell with different values to see what you get.\n",
    "* We'll add a red `x` to show centriods, when we can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means with generated hyperspheres\n",
    "\n",
    "Although we used 10 dimensions and only show 3, the generated hyperspheres are easy for the k-means algorithm to cluster as expected if you pick the correct number for clusters.  If you change `n_clusters`, you'll see that the clusters are combined or split in ways that might not make sense visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "y_pred = kmeans.fit_predict(blobs)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "show_scatter_3d(blobs_df, 'X', 'Y', 'Z', predicted=y_pred, centers=centers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means with generated moons\n",
    "\n",
    "The moons data, demonstrates a weakness of k-means. k-means does not recognize the dense crescent shapes which are easy to detect visually. k-means is limited to circles/spheres/hyperspheres. We choose n_clusters=2, but the result is probably not the best for this data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "kmeans = KMeans(n_clusters=k, n_init='auto')\n",
    "y_pred = kmeans.fit_predict(moons)\n",
    "centers = kmeans.cluster_centers_\n",
    "    \n",
    "show_scatter_moons(moons, y_pred, centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means clustering with our customer data\n",
    "\n",
    "k-means cluster using our selected customer features looks OK visually. It certainly would be nice if the `n_clusters` was more automatic. We're using n_clusters=3 (and you can experiment).\n",
    "\n",
    "One thing you might notice is that there are outlier data points or smaller clusters that don't look right. Adjusting n_clusters can help, but an algorithm that understands the concept of outliers would be more helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init='auto')\n",
    "predicted = kmeans.fit_predict(df_churn.values)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "show_scatter_3d(df_churn, x_name, y_name, z_name, predicted=predicted, centers=centers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External evaluation\n",
    "\n",
    "We can do \"external evaluation\" by comparing the predicted clusters with the CHURNRISK label that we removed from the data.\n",
    "You shouldn't expect unsupervised learning to be a good predictor of something so specific (supervised learning should work better),\n",
    "but this demonstrates that these discovered customer groupings might have some things in common.\n",
    "\n",
    "With n_clusters=3, you'll see that low risk customers were grouped pretty accurately. Another cluster is mostly high risk. The third group is high/medium.\n",
    "You can run this again after predicting different numbers of clusters. Also, we'll see later how this compares to other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_risk_by_cluster(predicted, known_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Plotly\n",
    "\n",
    "If you experimented above, you may have noticed that our k-means clusers were heavily influenced by the PROFIT_YTD column.\n",
    "Using Plotly to rotate the chart and look at it from other angles can help you see that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_churn.copy()\n",
    "X_df['CLUSTER'] = predicted\n",
    "plotly_scatter_3d(X_df, x_name, y_name, z_name, color='CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean shift\n",
    "\n",
    "Mean shift is centroid-based like k-means, but has some advantages:\n",
    "\n",
    "1. You don't need to specify n_clusters\n",
    "2. It is not limited to hyperspheres\n",
    "3. It recognizes density when seeking cluster centers\n",
    "4. `cluster_all=False` allows orphans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = estimate_bandwidth(moons, quantile=.2, n_samples=1000) \n",
    "ms = MeanShift(cluster_all=False, bandwidth=bandwidth)\n",
    "y_pred = ms.fit_predict(moons)\n",
    "centers = ms.cluster_centers_\n",
    "    \n",
    "show_scatter_moons(moons, y_pred, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(cluster_all=False)\n",
    "predicted = ms.fit_predict(df_churn.values)\n",
    "labels = ms.labels_\n",
    "centers = ms.cluster_centers_\n",
    "\n",
    "print(\"Number of clusters: \", len(centers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying mean shift on our customer data, the first advantage is obvious:\n",
    "\n",
    "* It automatically determined the number of clusters!\n",
    "\n",
    "Since we used `cluster_all=False`, you'll see that mean shift was able to orphan for some of our outlier points. You can experiment with that parameter to see how mean shift determines clusters when all points are clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_3d(df_churn, x_name, y_name, z_name, predicted=predicted, centers=centers,\n",
    "                show_colorbar=False,\n",
    "                cmap=ListedColormap(cm.Accent.colors[:6]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With matplotlib animation we can cycle through charts that show the clusters and the orphans to help illustrate the separation accomplished by detecting sparse and dense regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df_churn.copy()\n",
    "temp_df['CLUSTER'] = predicted\n",
    "no_outliers_df = temp_df[temp_df['CLUSTER']!=-1]\n",
    "outliers_df = temp_df[temp_df['CLUSTER']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = [\n",
    "    {'dataframe': temp_df, 'centers': centers, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': outliers_df, 'centers': centers, 'cmap': ListedColormap(cm.Accent.colors[:1])},\n",
    "    {'dataframe': temp_df, 'centers': centers, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': no_outliers_df, 'centers': centers, 'cmap': ListedColormap(cm.Accent.colors[1:6])},\n",
    "    {'dataframe': temp_df, 'centers': centers, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': no_outliers_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[1:6])},\n",
    "    {'dataframe': temp_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': no_outliers_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[1:6])},\n",
    "    {'dataframe': temp_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': outliers_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[:1])},\n",
    "    {'dataframe': temp_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[:6])},\n",
    "    {'dataframe': outliers_df, 'centers': None, 'cmap': ListedColormap(cm.Accent.colors[:1])}\n",
    "]\n",
    "\n",
    "# n loops for more time to watch charts\n",
    "loops = 2\n",
    "for loop in range(loops):\n",
    "  for chart in charts:\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = show_scatter_3d(chart['dataframe'], x_name, y_name, z_name, predicted=chart['dataframe']['CLUSTER'],\n",
    "                centers=chart['centers'],\n",
    "                show_colorbar=False, cmap=chart['cmap'],\n",
    "                elev=35, azim=10,\n",
    "                xlim3d=(10, 80), ylim3d=(-3000, 3000), zlim3d=(0, 20))\n",
    "        \n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_risk_by_cluster(predicted, known_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "Unlike mean shift, DBSCAN understands the concept of outliers. It will not create mini-clusters of outliers, but instead will take all the outliers and put them in cluster -1. These outliers are sometimes called \"noise\".\n",
    "\n",
    "In addition, since DBSCAN is density-based and not centroid-based, it is able to predict cluster shapes that k-means and mean shift cannot predict.\n",
    "\n",
    "For DBSCAN the eps parameter is important. With our customer data, we use the `eps` paramater to specify the maximum distance between samples. By trying different values, you will see that it has a strong influence on the number of clusters and the amount of noise. This behavior makes it difficult to use with out customer data set, but with eps=110 we can demonstrate clusters with noise removed.\n",
    "\n",
    "A better example of how density-based clustering can recognize groups that centroid-based clustering cannot is our moons example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "predicted = DBSCAN(eps=110).fit_predict(df_churn)\n",
    "\n",
    "print('Number of clusters:', len(set(predicted)) - (1 if -1 in predicted else 0))\n",
    "print('Number of outliers:', list(predicted).count(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df_churn.copy()\n",
    "temp_df['CLUSTER'] = predicted\n",
    "temp_df['KNOWN_RISK'] = known_risk\n",
    "temp_df.columns = [str(x) for x in temp_df.columns.values]\n",
    "no_outliers_df = temp_df[temp_df['CLUSTER']!=-1]\n",
    "outliers_df = temp_df[temp_df['CLUSTER']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_3d(no_outliers_df, x_name, y_name, z_name, predicted=no_outliers_df['CLUSTER'], azim=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_3d(outliers_df, x_name, y_name, z_name, predicted=outliers_df['CLUSTER'], cmap=cm.gist_stern, alpha=1, azim=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN with generated moons\n",
    "\n",
    "The moons data clearly demonstrates how density-based clustering can predict group \"shapes\" that centroid-based clustering cannot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = DBSCAN(eps=.1).fit_predict(moons)\n",
    "\n",
    "print('Number of clusters:', len(set(predicted)) - (1 if -1 in predicted else 0))\n",
    "print('Number of outliers:', list(predicted).count(-1))\n",
    "\n",
    "show_scatter_moons(moons, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ac = AgglomerativeClustering(n_clusters=None, distance_threshold=500, \n",
    "                             metric='euclidean', linkage='complete')\n",
    "predicted = ac.fit_predict(df_churn.values)\n",
    "\n",
    "print('Number of clusters:', len(set(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_risk_by_cluster(predicted, known_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scatter_3d(df_churn, x_name, y_name, z_name, predicted=predicted);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_churn.copy()\n",
    "X_df['CLUSTER'] = predicted\n",
    "plotly_scatter_3d(X_df, x_name, y_name, z_name, color='CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font size=-1 color=gray>\n",
    "&copy; Copyright 2019 IBM Corp. All Rights Reserved.\n",
    "<p>\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the\n",
    "License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "express or implied. See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "There is no automated testing for this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Submission\n",
    "- This homework is due by 2023-04-10, 5:30PM (EDT)\n",
    "- **For this assignment you need to submit your notebook**\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on ARC.\n",
    "\n",
    "**Run the cell below to submit your work.**\n",
    "\n",
    "- You may submit your work multipe times up to the deadline of the assignment.\n",
    "- Please note that any files that you previously submitted will\n",
    "be overwritten by your current files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to submit this notebook\n",
    "#\n",
    "from submit import submit\n",
    "submit()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
